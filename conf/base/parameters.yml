
# Parameters for the example pipeline. Feel free to delete these once you
# remove the example pipeline from hooks.py and the example nodes in
# `src/pipelines/`
# Documentation for this file format can be found in "Parameters"
# Link: https://kedro.readthedocs.io/en/stable/04_kedro_project_setup/02_configuration.html#parameters

# CNN Character Parameters :
# Model parameters
cnn_feature_num: 83
cnn_feature_size: 256
cnn_kernel_one: 7 # comme khaled couche de conv
cnn_kernel_two: 3
cnn_stride_one: 1
cnn_stride_two: 3
cnn_sequence_len: 1014
cnn_output_linear: 1024
cnn_dropout: 0.5
cnn_num_class: 2

# Train parameters
cnn_num_threads: 4
cnn_clip: 400
cnn_verbose: False
cnn_freq_verbose: 100
cnn_cuda_allow: True
cnn_patience: 3
cnn_lr: 0.0001
cnn_num_epochs: 50
cnn_size_batch: 86
  # Others
cnn_alphabet: None
      # To delete after testing performance
cnn_path_to_save_model: "data/06_models/cnn_char_classifier/cnn_char_model/cnn_char_model_pytorch.pt"

# Logistic BOW
logistic_bow_max_number_feature: 100

#CNN + Embed
col_allocine: "review"
device: "cuda"
batch_size: 50
sentence_size: 67
colname_allocine: "review"
embed_dim: 200
embcnn_nb_filtre: 200
embcnn_type_filtre:
  filtre1: 1
  filtre2: 2

embcnn_nb_output: 2
embcnn_dropout: 0.6
embcnn_min_freq: 3
embcnn_n_epochs: 50

embcnn_padded: True

embcnn_class_explanation: 0
embcnn_type_map: "max"
embcnn_seuil: 0.75
embcnn_index_nothing: None

#BiLSTM + CNN

bilstm_num_epochs : 50
bilstm_batch_size: 32
bilstm_patience : 5
bilstm_lr : 0.001
bilstm_input_dim : 200
bilstm_hidden_dim : 128
bilstm_layer_dim : 2
bilstm_feature_size : 256
bilstm_output_dim : 2
bilstm_kernel_size : 3
bilstm_dropout_rate : 0.5
word2vec_path: "data/06_models/word2vec/frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin"

# BERT + CNN
bertcnn_bert_path: "camembert/camembert-base"
bertcnn_max_seq_len: 67

# Model parameters
bertcnn_embedding_dim: 768
bertcnn_nb_filter: 50
bertcnn_type_filter:
  filtre1: 2
  filtre2: 3
bertcnn_output_dim: 2
bertcnn_dropout: 0.5

# Train parameters
bertcnn_num_threads: 4
bertcnn_clip: 400
bertcnn_verbose: False
bertcnn_freq_verbose: 100
bertcnn_cuda_allow: True
bertcnn_patience: 5
bertcnn_lr: 0.0001
bertcnn_num_epochs: 50
bertcnn_size_batch: 86
