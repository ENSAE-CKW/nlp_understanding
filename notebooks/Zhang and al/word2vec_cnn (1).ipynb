{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2s7Wuf7W6TKo",
        "FAfJ1Kow57ps",
        "V4FxKe2k5iCW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "stat_app",
      "language": "python",
      "name": "stat_app"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19ca09eaba604b0badc38da5d40cd8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c6a2c54f432841e2bba828691bbaabe7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84057421dace4b5381c5cfe1866e1a16",
              "IPY_MODEL_1a8bec0c087941819047d7dfcaa92546"
            ]
          }
        },
        "c6a2c54f432841e2bba828691bbaabe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84057421dace4b5381c5cfe1866e1a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9e6757f62fc84706b0a4a99931b72565",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1201,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1201,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_241226db26c645d1bd89fd987704651a"
          }
        },
        "1a8bec0c087941819047d7dfcaa92546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92a80857d5e8454484dcc2a52cb0aa5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.24k/? [00:00&lt;00:00, 13.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b45ef28554e9470383c56d67d2daa9ec"
          }
        },
        "9e6757f62fc84706b0a4a99931b72565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "241226db26c645d1bd89fd987704651a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92a80857d5e8454484dcc2a52cb0aa5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b45ef28554e9470383c56d67d2daa9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b59890c6aeed4711b7574f8277cf4044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9c616dc866748e5b609ac52e390b3be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_294dc9e5122748a0a9b11afd716f9920",
              "IPY_MODEL_4676532a932b47a29551bcb798855050"
            ]
          }
        },
        "c9c616dc866748e5b609ac52e390b3be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "294dc9e5122748a0a9b11afd716f9920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c06ebf6efdf4e16937a068c8ade454e",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 813,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 813,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_732f4b230f944169b00a079f15992825"
          }
        },
        "4676532a932b47a29551bcb798855050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3594506ec0e94cdeb0c9c396e187c02b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.81k/? [00:00&lt;00:00, 25.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b50d222868a45f2a7f845a5e7413ec7"
          }
        },
        "6c06ebf6efdf4e16937a068c8ade454e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "732f4b230f944169b00a079f15992825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3594506ec0e94cdeb0c9c396e187c02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b50d222868a45f2a7f845a5e7413ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0019ba23b4004cda9e809e32a79f87fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f65e18d4935a491ab215b3d9f187b9f3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d97674abcc76420480b8590cbd64400f",
              "IPY_MODEL_6765bf329ec4493ba9b41bc01c9f1168"
            ]
          }
        },
        "f65e18d4935a491ab215b3d9f187b9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d97674abcc76420480b8590cbd64400f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f38c941278447e4a1fa39a9a74932be",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 66625305,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 66625305,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38796b80e6e14a919b30f5dd415f253a"
          }
        },
        "6765bf329ec4493ba9b41bc01c9f1168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50ebf56c4c9c4d2d876b94fab405d57b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 66.6M/66.6M [00:13&lt;00:00, 5.08MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_622675148db647f893427176dbd87e7b"
          }
        },
        "1f38c941278447e4a1fa39a9a74932be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38796b80e6e14a919b30f5dd415f253a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50ebf56c4c9c4d2d876b94fab405d57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "622675148db647f893427176dbd87e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd84df675a204a88873d0df7ffdaacdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f09c1f298024415847c1e439aa852a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9362ae4aa7d5454b98bd79efe9d70fd7",
              "IPY_MODEL_5b7cd4d1670b4500a63cd0218edf6862"
            ]
          }
        },
        "0f09c1f298024415847c1e439aa852a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9362ae4aa7d5454b98bd79efe9d70fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_148e48b60df24fcb84f7e7a45c47d83b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42f42bb1c5a8449a8c043b6b3fccde65"
          }
        },
        "5b7cd4d1670b4500a63cd0218edf6862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea0c7253ace544ca9ed2eb3bca9c8c15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 160000/0 [00:05&lt;00:00, 36766.19 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbab5107c1d14c17991f42cd5de81d68"
          }
        },
        "148e48b60df24fcb84f7e7a45c47d83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42f42bb1c5a8449a8c043b6b3fccde65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea0c7253ace544ca9ed2eb3bca9c8c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbab5107c1d14c17991f42cd5de81d68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8bbc092db9342208d1076cdd4a832cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0db5ed74de7419ca21997274281f23c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b8de8284df045a9a84c45b482dfad00",
              "IPY_MODEL_bbd68dc42e254b91a8a9296cc72adfc9"
            ]
          }
        },
        "d0db5ed74de7419ca21997274281f23c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b8de8284df045a9a84c45b482dfad00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_418056929de142a4a6ad15347be56b46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f49b473db414404394d0320ab80a3c8c"
          }
        },
        "bbd68dc42e254b91a8a9296cc72adfc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a06a60d6c5ae455988f2fc8fd98e8361",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20000/0 [00:00&lt;00:00, 35223.91 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9370f78a5e7348649bcd4f8350184db5"
          }
        },
        "418056929de142a4a6ad15347be56b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f49b473db414404394d0320ab80a3c8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a06a60d6c5ae455988f2fc8fd98e8361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9370f78a5e7348649bcd4f8350184db5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a04d98e8d7c9420b9b1617d85f40290b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cad78a0cfdaf41a6befbee2bb943674e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_308a927824594123a7ba1266dc53ca7a",
              "IPY_MODEL_bb3c659f4b424adeb1fa2b57651ee319"
            ]
          }
        },
        "cad78a0cfdaf41a6befbee2bb943674e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "308a927824594123a7ba1266dc53ca7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7adff14061c040019d094a4013cf878e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f2f12c1406e49b194a00d462c040ec6"
          }
        },
        "bb3c659f4b424adeb1fa2b57651ee319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_961365ab9a024c0f9dbae24350881417",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20000/0 [00:00&lt;00:00, 35291.56 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa730cbb4d6543f488e330e53c55f5fe"
          }
        },
        "7adff14061c040019d094a4013cf878e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f2f12c1406e49b194a00d462c040ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "961365ab9a024c0f9dbae24350881417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa730cbb4d6543f488e330e53c55f5fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB-uHi8js9zF"
      },
      "source": [
        "# Implémentation du papier *A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification* de Zhang et Wallace [(2012)](https://arxiv.org/pdf/1510.03820.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc3lYuhUwhrL"
      },
      "source": [
        "L'article propose une heuristique afin d'utiliser des réseaux de neurones convolutionnel pour la classification de phrases. Ces réseaux se basent sur une couche convoltuionnelle.\n",
        "\n",
        "L'entrée du réseau est une matrice dont les lignes correspondent à un plongement lexical ou *embedding* de chaque mot. Les auteurs proposent de considérer trois *embeddings* :\n",
        "- One hot encoding\n",
        "- Word2Vec de Google\n",
        "- GloVe\n",
        "\n",
        "\n",
        "Nous allons essayer d'implémenter le modèle de Zhang et Wallace (2012) en utilisant trois jeux de données : \n",
        "- allocine_review\n",
        "- flue\n",
        "- orange_sum\n",
        "\n",
        "Le jeu de données `allocine_review` est directement disponible en utilisant la librarie [`datasets`](https://github.com/huggingface/datasets) de `huggingface`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GHBYKnCENXQ"
      },
      "source": [
        "### Implémentation du CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6SxaI4NFV22"
      },
      "source": [
        "!pip install datasets\r\n",
        "!pip install torch\r\n",
        "!pip install gensim\r\n",
        "!pip install -U spaCy\r\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AjZKvdxLbu9"
      },
      "source": [
        "from datasets import load_dataset"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrFpS0rEENXQ"
      },
      "source": [
        "import torch\n",
        "import spacy \n",
        "import nltk\n",
        "import re\n",
        "import gensim\n",
        "from spacy import displacy\n",
        "from math import floor\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd \n",
        "import random \n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from itertools import combinations\n",
        "import torch.nn as nn\n",
        "from torchtext import data    \n",
        "from torchtext.vocab import Vectors"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iFUuz7XQENXQ"
      },
      "source": [
        "#Reproducing same results\n",
        "SEED = 2019\n",
        "\n",
        "BATCH_SIZE = 50 #Same as Zhang and Wallace (2016)\n",
        "SENTENCE_SIZE = 67 #attention changer correspond à 80% du training set en entier apres tok\n",
        "\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "#Cuda\n",
        "torch.backends.cudnn.deterministic = True  \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bANOgGKQj4DG",
        "outputId": "1505b153-feb5-475e-af33-9506ef45531d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "dossier_donnees = \"/content/drive/My Drive/projet_nlp\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ara3K841Gdwq"
      },
      "source": [
        "### Téléchargement de données complémentaires et initialisation de spacy\r\n",
        "\r\n",
        "-Téléchargement du modèle Word2Vec en français\r\n",
        "- Téléchargement du jeu de données *allocine_review*\r\n",
        "- Mise en place de spacy\r\n",
        "- Création d'un fichier word2vec.txt contenant l'embedding pour pouvoir l'ouvrir avec `Vectors` de `torchtext`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puNXXdguENXR"
      },
      "source": [
        "model_fr = gensim.models.KeyedVectors.load_word2vec_format(\"https://s3.us-east-2.amazonaws.com/embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_200_skip_cut100.bin\",binary=True, unicode_errors='ignore')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "19ca09eaba604b0badc38da5d40cd8e3",
            "c6a2c54f432841e2bba828691bbaabe7",
            "84057421dace4b5381c5cfe1866e1a16",
            "1a8bec0c087941819047d7dfcaa92546",
            "9e6757f62fc84706b0a4a99931b72565",
            "241226db26c645d1bd89fd987704651a",
            "92a80857d5e8454484dcc2a52cb0aa5a",
            "b45ef28554e9470383c56d67d2daa9ec",
            "b59890c6aeed4711b7574f8277cf4044",
            "c9c616dc866748e5b609ac52e390b3be",
            "294dc9e5122748a0a9b11afd716f9920",
            "4676532a932b47a29551bcb798855050",
            "6c06ebf6efdf4e16937a068c8ade454e",
            "732f4b230f944169b00a079f15992825",
            "3594506ec0e94cdeb0c9c396e187c02b",
            "9b50d222868a45f2a7f845a5e7413ec7",
            "0019ba23b4004cda9e809e32a79f87fa",
            "f65e18d4935a491ab215b3d9f187b9f3",
            "d97674abcc76420480b8590cbd64400f",
            "6765bf329ec4493ba9b41bc01c9f1168",
            "1f38c941278447e4a1fa39a9a74932be",
            "38796b80e6e14a919b30f5dd415f253a",
            "50ebf56c4c9c4d2d876b94fab405d57b",
            "622675148db647f893427176dbd87e7b",
            "cd84df675a204a88873d0df7ffdaacdf",
            "0f09c1f298024415847c1e439aa852a4",
            "9362ae4aa7d5454b98bd79efe9d70fd7",
            "5b7cd4d1670b4500a63cd0218edf6862",
            "148e48b60df24fcb84f7e7a45c47d83b",
            "42f42bb1c5a8449a8c043b6b3fccde65",
            "ea0c7253ace544ca9ed2eb3bca9c8c15",
            "dbab5107c1d14c17991f42cd5de81d68",
            "e8bbc092db9342208d1076cdd4a832cc",
            "d0db5ed74de7419ca21997274281f23c",
            "5b8de8284df045a9a84c45b482dfad00",
            "bbd68dc42e254b91a8a9296cc72adfc9",
            "418056929de142a4a6ad15347be56b46",
            "f49b473db414404394d0320ab80a3c8c",
            "a06a60d6c5ae455988f2fc8fd98e8361",
            "9370f78a5e7348649bcd4f8350184db5",
            "a04d98e8d7c9420b9b1617d85f40290b",
            "cad78a0cfdaf41a6befbee2bb943674e",
            "308a927824594123a7ba1266dc53ca7a",
            "bb3c659f4b424adeb1fa2b57651ee319",
            "7adff14061c040019d094a4013cf878e",
            "8f2f12c1406e49b194a00d462c040ec6",
            "961365ab9a024c0f9dbae24350881417",
            "fa730cbb4d6543f488e330e53c55f5fe"
          ]
        },
        "id": "h2Lz5NfPENXR",
        "outputId": "63bb7798-78fe-486a-d8d2-a355b75be4c2"
      },
      "source": [
        "dataset_allocine = load_dataset(\"allocine\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19ca09eaba604b0badc38da5d40cd8e3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1201.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b59890c6aeed4711b7574f8277cf4044",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=813.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset allocine_dataset/allocine (download: 63.54 MiB, generated: 109.12 MiB, post-processed: Unknown size, total: 172.66 MiB) to /root/.cache/huggingface/datasets/allocine_dataset/allocine/1.0.0/bbee2ebb45a067891973b91ebdd40a93598d1e2dd5710b6714cdc2cd81d0ed65...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0019ba23b4004cda9e809e32a79f87fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=66625305.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd84df675a204a88873d0df7ffdaacdf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8bbc092db9342208d1076cdd4a832cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a04d98e8d7c9420b9b1617d85f40290b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset allocine_dataset downloaded and prepared to /root/.cache/huggingface/datasets/allocine_dataset/allocine/1.0.0/bbee2ebb45a067891973b91ebdd40a93598d1e2dd5710b6714cdc2cd81d0ed65. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0fgauMiENXR"
      },
      "source": [
        "#Si OSError: [E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory sur \n",
        "#Collab alors il suffit de relancer le notebook --> Ctrl + M\n",
        "nlp = spacy.load('fr_core_news_sm', disable=[\"tagger\", \"parser\",\"ner\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y_GlQSzI1h3"
      },
      "source": [
        "#### Création du fichier word2Vec.txt et des fichiers à lire dans `torchtext`\r\n",
        "\r\n",
        "Cette étape est necessaire car dans `torch.text`, l'embedding Word2Text en français n'est pas disponible ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVnJFG_xJhrR"
      },
      "source": [
        "model_fr = gensim.models.KeyedVectors.load_word2vec_format(\"https://s3.us-east-2.amazonaws.com/embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_200_skip_cut100.bin\",binary=True, unicode_errors='ignore')\r\n",
        "name_embedding = list(model_fr.vocab.keys())"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_ZtxO-tK9S_",
        "outputId": "924ed735-135f-4089-b191-6a62e471107f"
      },
      "source": [
        "vector_embedding = model_fr.syn0"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_4VQKUnJSE0"
      },
      "source": [
        "f = open(dossier_donnees + \"/table/\" + \"word2vec_extra.txt\", \"w+\", encoding = \"utf-8\")\r\n",
        "\r\n",
        "for i in range(len(name_embedding)):\r\n",
        "    f.write( name_embedding[i] + ' ' + \" \".join([str(i) for i in vector_embedding[i]]) + \" \\n\")\r\n",
        "\r\n",
        "f.close() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UOyA00WENXR"
      },
      "source": [
        "pd.DataFrame.from_dict(dataset_allocine[\"train\"]).to_csv(dossier_donnees + \"/table/\" + \"allocine_train.csv\",header = True, index = False)\n",
        "pd.DataFrame.from_dict(dataset_allocine[\"validation\"]).to_csv(dossier_donnees + \"/table/\" + \"allocine_validation.csv\",header = True, index = False)\n",
        "pd.DataFrame.from_dict(dataset_allocine[\"test\"]).to_csv(dossier_donnees + \"/table/\" + \"allocine_test.csv\",header = True, index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqRUtGR8G2IO"
      },
      "source": [
        "### Tokenisation du jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxNTox55ENXR"
      },
      "source": [
        "def tokenizer(exemple,nom_col):\n",
        "    return [X.lemma_ for X in nlp(exemple) if X.is_alpha & (not(X.is_stop))]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-IAtcTT2RZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1410e0a8-2fef-4dea-f271-de4bac913dec"
      },
      "source": [
        "model_fr = gensim.models.KeyedVectors.load_word2vec_format(\"https://s3.us-east-2.amazonaws.com/embeddings.net/embeddings/frWac_non_lem_no_postag_no_phrase_200_skip_cut100.bin\",binary=True, unicode_errors='ignore')\r\n",
        "nlp = spacy.load('fr_core_news_sm', disable=[\"tagger\", \"parser\",\"ner\"])\r\n",
        "vector_embedding = model_fr.syn0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlbNJ8oAENXR"
      },
      "source": [
        "vectors = Vectors(name= dossier_donnees + \"/table/\" + \"word2vec_extra.txt\")\n",
        "text = data.Field(tokenize= lambda x : tokenizer(x,\"review\"), lower = True, fix_length = SENTENCE_SIZE)\n",
        "label = data.LabelField(dtype = torch.float,batch_first=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CRXful5ENXS"
      },
      "source": [
        "fields = {'review' : ('t',text), 'label' : ('l',label)}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gISgHXiZENXS"
      },
      "source": [
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                                        path = dossier_donnees + \"/table/\",\n",
        "                                        train = 'allocine_train.csv',\n",
        "                                        validation = 'allocine_validation.csv',\n",
        "                                        test = 'allocine_test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields,\n",
        "                                        skip_header = False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q_2jGueIzev"
      },
      "source": [
        "text.build_vocab(train_data,min_freq=3,vectors = vectors)  #Is min_freq a hyperparameter ?\r\n",
        "label.build_vocab(train_data)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK3xDRjQENXS"
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort = False, #don't sort test/validation data\n",
        "    batch_size= BATCH_SIZE,\n",
        "    device = device\n",
        "    )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2o1lbLbENXS"
      },
      "source": [
        "Bien gérer plus tard les paddings et unknown ici!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMu3-SgMENXT"
      },
      "source": [
        "### CNN !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSQlcWnhENXT"
      },
      "source": [
        "class classifier(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self, wv, no_words, embedding_dim, nb_filter, height_filter, output_dim, dropout):\n",
        "        \n",
        "        #Constructor\n",
        "        super().__init__()          \n",
        "        \n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding.from_pretrained(wv)\n",
        "        \n",
        "        #Ne pas oublier d'ajouter un view !\n",
        "        #Convolutionnal layer\n",
        "        #it uses initialization as proposed by Kaiming et.al\n",
        "        self.conv1 = nn.Sequential(\n",
        "                nn.Conv2d(1,nb_filter,(height_filter,embedding_dim)),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d((no_words - height_filter + 1,1), stride = 1),\n",
        "            )\n",
        "        \n",
        "        \n",
        "        self.fc = nn.Linear(nb_filter, output_dim)\n",
        "    \n",
        "        self.sm = nn.Softmax(dim = 1)  \n",
        "\n",
        "        self.dp = nn.Dropout(p = dropout)\n",
        "\n",
        "\n",
        "    def forward(self,text):\n",
        "        x = self.embedding(text)\n",
        "        x = x.transpose(1,0).unsqueeze(1) #[nb_batch, nb_channel = 1, nb_words_in_sentences, embedding_dim]\n",
        "        x = self.conv1(x) #[nb_batch, nb_filter, no_words - height_filter + 1, 1] (last dim because conv on the whole width)\n",
        "        x = x.squeeze() #[nb_batch, no_words - height_filter + 1]\n",
        "        x = self.dp(x)\n",
        "        x = self.fc(x) #[nb_batch, 2]\n",
        "        x = self.sm(x)\n",
        "        return x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyHVOxijdXHR"
      },
      "source": [
        "class classifier3F(nn.Module):\r\n",
        "    #TODO : remove embedding_dim using wv.shape[1]\r\n",
        "    #define all the layers used in model\r\n",
        "    def __init__(self, wv, no_words, embedding_dim, nb_filter, height_filter, output_dim, dropout):\r\n",
        "        \r\n",
        "        #Constructor\r\n",
        "        super().__init__()          \r\n",
        "        \r\n",
        "        #embedding layer\r\n",
        "        self.embedding = nn.Embedding.from_pretrained(wv)\r\n",
        "        \r\n",
        "        #Ne pas oublier d'ajouter un view !\r\n",
        "        #Convolutionnal layer\r\n",
        "        #it uses initialization as proposed by Kaiming et.al\r\n",
        "\r\n",
        "        self.conv = nn.ModuleList()\r\n",
        "\r\n",
        "        for height in height_filter:\r\n",
        "          conv_lay = nn.Sequential(\r\n",
        "                nn.Conv2d(1,nb_filter,(height,embedding_dim)),\r\n",
        "                nn.ReLU(),\r\n",
        "                nn.MaxPool2d((no_words - height + 1,1), stride = 1),\r\n",
        "            )\r\n",
        "          self.conv.append(conv_lay)\r\n",
        "\r\n",
        "        self.fc = nn.Linear(len(height_filter)*nb_filter, output_dim)\r\n",
        "    \r\n",
        "        self.sm = nn.Softmax(dim = 1)  \r\n",
        "\r\n",
        "        self.dp = nn.Dropout(p = dropout)\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self,text):\r\n",
        "        x = self.embedding(text)\r\n",
        "        x = x.transpose(1,0).unsqueeze(1) #[nb_batch, nb_channel = 1, nb_words_in_sentences, embedding_dim]\r\n",
        "        x = [conv(x).squeeze() for conv in self.conv]\r\n",
        "        x = torch.cat(tuple(x), dim = 1)\r\n",
        "        x = self.dp(x)\r\n",
        "        x = self.fc(x) #[nb_batch, 2]\r\n",
        "        x = self.sm(x)\r\n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SefREeZVENXT"
      },
      "source": [
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds[:,1])    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlyDo38tENXT"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    #initialize epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        #resets the gradients after every batch\n",
        "        #each batch is used in order to provide an estimation of gradient C according to the paramaeters\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        #retrieve text and no. of words\n",
        "        text = batch.t\n",
        "\n",
        "        #convert to 1D tensor\n",
        "        predictions = model(text).squeeze()  \n",
        "        \n",
        "        #compute the loss\n",
        "        loss = criterion(predictions, batch.l.long())        \n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.l)   \n",
        "        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp3ASexUENXT"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text = batch.t\n",
        "            \n",
        "            #convert to 1d tensor\n",
        "            predictions = model(text).squeeze()\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.l.long())\n",
        "            acc = binary_accuracy(predictions, batch.l)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator) , epoch_acc / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK4pBFCkPoTK"
      },
      "source": [
        "def train_BCE(model, iterator, optimizer, criterion):\r\n",
        "    \r\n",
        "    #initialize epoch \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    #set the model in training phase\r\n",
        "    model.train()  \r\n",
        "    \r\n",
        "    for batch in iterator:\r\n",
        "        \r\n",
        "        #resets the gradients after every batch\r\n",
        "        #each batch is used in order to provide an estimation of gradient C according to the paramaeters\r\n",
        "        optimizer.zero_grad()   \r\n",
        "        \r\n",
        "        #retrieve text and no. of words\r\n",
        "        text = batch.t\r\n",
        "\r\n",
        "        #convert to 1D tensor\r\n",
        "        predictions = model(text).squeeze()  \r\n",
        "        \r\n",
        "        #compute the loss\r\n",
        "        loss = criterion(predictions[:,1], batch.l)        \r\n",
        "        \r\n",
        "        #compute the binary accuracy\r\n",
        "        acc = binary_accuracy(predictions, batch.l)   \r\n",
        "        \r\n",
        "        #backpropage the loss and compute the gradients\r\n",
        "        loss.backward()       \r\n",
        "        \r\n",
        "        #update the weights\r\n",
        "        optimizer.step()      \r\n",
        "        \r\n",
        "        #loss and accuracy\r\n",
        "        epoch_loss += loss.item()  \r\n",
        "        epoch_acc += acc.item()    \r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjCnMJoIQmmz"
      },
      "source": [
        "def evaluate_BCE(model, iterator, criterion):\r\n",
        "    \r\n",
        "    #initialize every epoch\r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "\r\n",
        "    #deactivating dropout layers\r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    #deactivates autograd\r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for batch in iterator:\r\n",
        "        \r\n",
        "            #retrieve text and no. of words\r\n",
        "            text = batch.t\r\n",
        "            \r\n",
        "            #convert to 1d tensor\r\n",
        "            predictions = model(text).squeeze()\r\n",
        "            \r\n",
        "            #compute loss and accuracy\r\n",
        "            loss = criterion(predictions[:,1], batch.l)\r\n",
        "            acc = binary_accuracy(predictions, batch.l)\r\n",
        "            \r\n",
        "            #keep track of loss and accuracy\r\n",
        "            epoch_loss += loss.item()\r\n",
        "            epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUrVSTT55Pgh"
      },
      "source": [
        "### Entrainement "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2loFJiC6ek-"
      },
      "source": [
        "#### Variation de la largeur des filtres au voisinage large de la taille optimale 2\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Bf0MZE4dIc"
      },
      "source": [
        "N_EPOCHS = 50\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "list_model = list(itertools.chain.from_iterable([list(combinations(range(1,5),i)) for i in range(1,4)]))\r\n",
        "\r\n",
        "pd.DataFrame({\"filter\" : \"\", \"btl\" : 0,\"bta\" : 0, \"bvl\" : 0, \"bva\" : 0}, index = [0]).to_csv(dossier_donnees + \"/resultat_multi_filtre\")\r\n",
        "\r\n",
        "for filtre in list_model:\r\n",
        "  model = classifier3F(torch.from_numpy(vector_embedding),SENTENCE_SIZE,vector_embedding.shape[1],400,filtre,2,0.5) #check the difference between syn0 and the other choice. \r\n",
        "  #I think it deals with negative sampling\r\n",
        "  print(model)\r\n",
        "  import torch.optim as optim\r\n",
        "\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  #optimizer = optim.Adam(model.parameters())\r\n",
        "  optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "  model = model.to(device)\r\n",
        "  criterion = criterion.to(device)\r\n",
        "\r\n",
        "  best_valid_loss = float('inf')\r\n",
        "  best_acc = float('inf')\r\n",
        "  best_train_loss = float('inf')\r\n",
        "  best_train_acc = float('inf')\r\n",
        "\r\n",
        "  for epoch in range(N_EPOCHS):\r\n",
        "      \r\n",
        "      #train the model\r\n",
        "      train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "      \r\n",
        "      #evaluate the model\r\n",
        "      valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "      \r\n",
        "      #save the best model\r\n",
        "      if valid_loss < best_valid_loss:\r\n",
        "          best_valid_loss = valid_loss\r\n",
        "          best_acc = valid_acc\r\n",
        "          best_train_loss = train_loss\r\n",
        "          best_train_acc = train_acc\r\n",
        "          #torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "      \r\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "  \r\n",
        "  pd.DataFrame({\"filter\": str(filtre) , \"btl\" : best_train_loss,\"bta\" : best_train_acc, \"bvl\" : best_valid_loss, \"bva\" : best_acc}, index = [0]).to_csv(dossier_donnees + \"/resultat_multi_filtre\",mode='a', header=False)\r\n",
        "\r\n",
        "#changer taille phrase ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s7Wuf7W6TKo"
      },
      "source": [
        "#### Variation de la largeur des filtres au voisinage de la taille optimale 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XENF-usTqYU"
      },
      "source": [
        "N_EPOCHS = 50\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "list_model = [(1,1),(1,1,1),(1,2),(1,1,2),(1,2,2)]\r\n",
        "\r\n",
        "pd.DataFrame({\"filter\" : \"\", \"btl\" : 0,\"bta\" : 0, \"bvl\" : 0, \"bva\" : 0}, index = [0]).to_csv(dossier_donnees + \"/resultat_multi_filtre_2\")\r\n",
        "\r\n",
        "for filtre in list_model:\r\n",
        "  model = classifier3F(torch.from_numpy(vector_embedding),SENTENCE_SIZE,vector_embedding.shape[1],400,filtre,2,0.5) #check the difference between syn0 and the other choice. \r\n",
        "  #I think it deals with negative sampling\r\n",
        "  print(model)\r\n",
        "  import torch.optim as optim\r\n",
        "\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  #optimizer = optim.Adam(model.parameters())\r\n",
        "  optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "  model = model.to(device)\r\n",
        "  criterion = criterion.to(device)\r\n",
        "\r\n",
        "  best_valid_loss = float('inf')\r\n",
        "  best_acc = float('inf')\r\n",
        "  best_train_loss = float('inf')\r\n",
        "  best_train_acc = float('inf')\r\n",
        "\r\n",
        "  for epoch in range(N_EPOCHS):\r\n",
        "      \r\n",
        "      #train the model\r\n",
        "      train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "      \r\n",
        "      #evaluate the model\r\n",
        "      valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "      \r\n",
        "      #save the best model\r\n",
        "      if valid_loss < best_valid_loss:\r\n",
        "          best_valid_loss = valid_loss\r\n",
        "          best_acc = valid_acc\r\n",
        "          best_train_loss = train_loss\r\n",
        "          best_train_acc = train_acc\r\n",
        "          #torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "      \r\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "  \r\n",
        "  pd.DataFrame({\"filter\": str(filtre) , \"btl\" : best_train_loss,\"bta\" : best_train_acc, \"bvl\" : best_valid_loss, \"bva\" : best_acc}, index = [0]).to_csv(dossier_donnees + \"/resultat_multi_filtre_2\",mode='a', header=False)\r\n",
        "\r\n",
        "#changer taille phrase ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAfJ1Kow57ps"
      },
      "source": [
        "#### Variation du nombre de filtres à utiliser à partir du filtre (1,2)\r\n",
        "\r\n",
        "Les tailles de filtre utilisés sont : [10,50,100,200,400,600,1000,2000] conformément à Zheng et *al.* (2012)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IFZ4m2x56hG"
      },
      "source": [
        "N_EPOCHS = 50\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "pd.DataFrame({\"nb_filter\" : 0, \"btl\" : 0,\"bta\" : 0, \"bvl\" : 0, \"bva\" : 0}, index = [0]).to_csv(dossier_donnees + \"/resultat_taille.filtre.csv\")\r\n",
        "\r\n",
        "for nb_filtre in [10,50,100,200,400,600,1000,2000]:\r\n",
        "  model = classifier3F(torch.from_numpy(vector_embedding),SENTENCE_SIZE,vector_embedding.shape[1],nb_filtre,(1,2),2,0.5) #check the difference between syn0 and the other choice. \r\n",
        "  #I think it deals with negative sampling\r\n",
        "  print(model)\r\n",
        "  import torch.optim as optim\r\n",
        "\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  #optimizer = optim.Adam(model.parameters())\r\n",
        "  optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "  model = model.to(device)\r\n",
        "  criterion = criterion.to(device)\r\n",
        "\r\n",
        "  best_valid_loss = float('inf')\r\n",
        "  best_acc = float('inf')\r\n",
        "  best_train_loss = float('inf')\r\n",
        "  best_train_acc = float('inf')\r\n",
        "\r\n",
        "  for epoch in range(N_EPOCHS):\r\n",
        "      \r\n",
        "      #train the model\r\n",
        "      train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "      \r\n",
        "      #evaluate the model\r\n",
        "      valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "      \r\n",
        "      #save the best model\r\n",
        "      if valid_loss < best_valid_loss:\r\n",
        "          best_valid_loss = valid_loss\r\n",
        "          best_acc = valid_acc\r\n",
        "          best_train_loss = train_loss\r\n",
        "          best_train_acc = train_acc\r\n",
        "          #torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "      \r\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "\r\n",
        "  pd.DataFrame({\"nb_filter\" : nb_filtre, \"btl\" : best_train_loss,\"bta\" : best_train_acc, \"bvl\" : best_valid_loss, \"bva\" : best_acc}, index = [0]).to_csv(dossier_donnees + \"/resultat_taille.filtre.csv\", mode='a', header=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mGg91pVlQMI"
      },
      "source": [
        "N_EPOCHS = 50\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for nb_filtre in [1000,1500,2000]:\r\n",
        "  model = classifier3F(torch.from_numpy(vector_embedding),SENTENCE_SIZE,vector_embedding.shape[1],nb_filtre,(1,2),2,0.5) #check the difference between syn0 and the other choice. \r\n",
        "  #I think it deals with negative sampling\r\n",
        "  print(model)\r\n",
        "  import torch.optim as optim\r\n",
        "\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  #optimizer = optim.Adam(model.parameters())\r\n",
        "  optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "  model = model.to(device)\r\n",
        "  criterion = criterion.to(device)\r\n",
        "\r\n",
        "  best_valid_loss = float('inf')\r\n",
        "  best_acc = float('inf')\r\n",
        "  best_train_loss = float('inf')\r\n",
        "  best_train_acc = float('inf')\r\n",
        "\r\n",
        "  for epoch in range(N_EPOCHS):\r\n",
        "      \r\n",
        "      #train the model\r\n",
        "      train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "      \r\n",
        "      #evaluate the model\r\n",
        "      valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "      \r\n",
        "      #save the best model\r\n",
        "      if valid_loss < best_valid_loss:\r\n",
        "          best_valid_loss = valid_loss\r\n",
        "          best_acc = valid_acc\r\n",
        "          best_train_loss = train_loss\r\n",
        "          best_train_acc = train_acc\r\n",
        "          #torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "      \r\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "\r\n",
        "  pd.DataFrame({\"nb_filter\" : nb_filtre, \"btl\" : best_train_loss,\"bta\" : best_train_acc, \"bvl\" : best_valid_loss, \"bva\" : best_acc}, index = [0]).to_csv(dossier_donnees + \"/resultat_taille.filtre.csv\", mode='a', header=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoojkG1csMhx"
      },
      "source": [
        "#### Variation de la régularisation\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4FxKe2k5iCW"
      },
      "source": [
        "#### Dropout entre 0.1 et 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtHbM_o4sbg9"
      },
      "source": [
        "N_EPOCHS = 30\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "pd.DataFrame({\"dropout\" : 0, \"btl\" : 0,\"bta\" : 0, \"bvl\" : 0, \"bva\" : 0}, index = [0]).to_csv(dossier_donnees + \"/resultat_dropout.csv\")\r\n",
        "\r\n",
        "for dropout in [0.1,0.2,0.3,0.4,0.5]:\r\n",
        "  model = classifier3F(torch.from_numpy(vector_embedding),SENTENCE_SIZE,vector_embedding.shape[1],200,(1,2),2,dropout) #check the difference between syn0 and the other choice. \r\n",
        "  #I think it deals with negative sampling\r\n",
        "  print(model)\r\n",
        "  import torch.optim as optim\r\n",
        "\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  #optimizer = optim.Adam(model.parameters())\r\n",
        "  optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "  model = model.to(device)\r\n",
        "  criterion = criterion.to(device)\r\n",
        "\r\n",
        "  best_valid_loss = float('inf')\r\n",
        "  best_acc = float('inf')\r\n",
        "  best_train_loss = float('inf')\r\n",
        "  best_train_acc = float('inf')\r\n",
        "\r\n",
        "  for epoch in range(N_EPOCHS):\r\n",
        "      \r\n",
        "      #train the model\r\n",
        "      train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "      \r\n",
        "      #evaluate the model\r\n",
        "      valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "      \r\n",
        "      #save the best model\r\n",
        "      if valid_loss < best_valid_loss:\r\n",
        "          best_valid_loss = valid_loss\r\n",
        "          best_acc = valid_acc\r\n",
        "          best_train_loss = train_loss\r\n",
        "          best_train_acc = train_acc\r\n",
        "          #torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "      \r\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "\r\n",
        "  pd.DataFrame({\"dropout\" : dropout, \"btl\" : best_train_loss,\"bta\" : best_train_acc, \"bvl\" : best_valid_loss, \"bva\" : best_acc}, index = [0]).to_csv(dossier_donnees +  \"/resultat_dropout.csv\", mode='a', header=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wz2b8W-5lkB"
      },
      "source": [
        "#### Dropout entre 0.6 et 0.9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI_Api5e5qRV"
      },
      "source": [
        "N_EPOCHS = 30\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for dropout in [0.5,0.6,0.7,0.8,0.9]:\r\n",
        "  model = classifier3F(torch.from_numpy(vector_embedding),SENTENCE_SIZE,vector_embedding.shape[1],200,(1,2),2,dropout) #check the difference between syn0 and the other choice. \r\n",
        "  #I think it deals with negative sampling\r\n",
        "  print(model)\r\n",
        "  import torch.optim as optim\r\n",
        "\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  #optimizer = optim.Adam(model.parameters())\r\n",
        "  optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "  model = model.to(device)\r\n",
        "  criterion = criterion.to(device)\r\n",
        "\r\n",
        "  best_valid_loss = float('inf')\r\n",
        "  best_acc = float('inf')\r\n",
        "  best_train_loss = float('inf')\r\n",
        "  best_train_acc = float('inf')\r\n",
        "\r\n",
        "  for epoch in range(N_EPOCHS):\r\n",
        "      \r\n",
        "      #train the model\r\n",
        "      train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "      \r\n",
        "      #evaluate the model\r\n",
        "      valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "      \r\n",
        "      #save the best model\r\n",
        "      if valid_loss < best_valid_loss:\r\n",
        "          best_valid_loss = valid_loss\r\n",
        "          best_acc = valid_acc\r\n",
        "          best_train_loss = train_loss\r\n",
        "          best_train_acc = train_acc\r\n",
        "          #torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "      \r\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "\r\n",
        "  pd.DataFrame({\"dropout\" : dropout, \"btl\" : best_train_loss,\"bta\" : best_train_acc, \"bvl\" : best_valid_loss, \"bva\" : best_acc}, index = [0]).to_csv(dossier_donnees +  \"/resultat_dropout.csv\", mode='a', header=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7jd72k969gt"
      },
      "source": [
        "## Version corrigée"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EueMMdMKPfcr"
      },
      "source": [
        "### Version avec BCELoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKVRk1gBK8Nh"
      },
      "source": [
        "N_EPOCHS = 30\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "model = classifier3F(torch.from_numpy(vector_embedding),SENTENCE_SIZE,vector_embedding.shape[1],1000,(1,2),2,0.5) #check the difference between syn0 and the other choice. \r\n",
        "#I think it deals with negative sampling\r\n",
        "print(model)\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "criterion = nn.BCELoss()\r\n",
        "#optimizer = optim.Adam(model.parameters())\r\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "best_acc = float('inf')\r\n",
        "best_train_loss = float('inf')\r\n",
        "best_train_acc = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    #train the model\r\n",
        "    train_loss, train_acc = train_BCE(model, train_iterator, optimizer, criterion)\r\n",
        "    \r\n",
        "    #evaluate the model\r\n",
        "    valid_loss, valid_acc = evaluate_BCE(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    #save the best model\r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        best_acc = valid_acc\r\n",
        "        best_train_loss = train_loss\r\n",
        "        best_train_acc = train_acc\r\n",
        "        torch.save(model.state_dict(), 'final_allocine.pt')\r\n",
        "    \r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3SM0ce9fxL0"
      },
      "source": [
        "### Taille de filtre optimale avec BCELoss avec le bon embedding ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB_jtjQV3h6K",
        "outputId": "4221745c-19c7-495f-def4-29fd4889fae7"
      },
      "source": [
        "text.vocab.vectors.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([49075, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO_JSe_Jf1eC"
      },
      "source": [
        "N_EPOCHS = 30\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "model = classifier3F(text.vocab.vectors,SENTENCE_SIZE,vector_embedding.shape[1],600,(1,2),2,0.5) #check the difference between syn0 and the other choice. \r\n",
        "#I think it deals with negative sampling\r\n",
        "print(model)\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "criterion = nn.BCELoss()\r\n",
        "#optimizer = optim.Adam(model.parameters())\r\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "best_acc = float('inf')\r\n",
        "best_train_loss = float('inf')\r\n",
        "best_train_acc = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    #train the model\r\n",
        "    train_loss, train_acc = train_BCE(model, train_iterator, optimizer, criterion)\r\n",
        "    \r\n",
        "    #evaluate the model\r\n",
        "    valid_loss, valid_acc = evaluate_BCE(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    #save the best model\r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        best_acc = valid_acc\r\n",
        "        best_train_loss = train_loss\r\n",
        "        best_train_acc = train_acc\r\n",
        "        torch.save(model.state_dict(), 'final_allocine.pt')\r\n",
        "    \r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "\r\n",
        "\r\n",
        "#sauvegarder les iterators"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRPtGpt18M76"
      },
      "source": [
        "### Largeur de filtre optimale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGZ87Cgg8RGT"
      },
      "source": [
        "N_EPOCHS = 30\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "pd.DataFrame({\"filtre\" : 0, \"btl\" : 0,\"bta\" : 0, \"bvl\" : 0, \"bva\" : 0}, index = [0]).to_csv(dossier_donnees + \"/resultat_larg_filtre.csv\")\r\n",
        "\r\n",
        "for largeur in range(1,11):\r\n",
        "  model = classifier3F(text.vocab.vectors,SENTENCE_SIZE,vector_embedding.shape[1],100,tuple([largeur]),2,0.5) #check the difference between syn0 and the other choice. \r\n",
        "  #I think it deals with negative sampling\r\n",
        "  print(model)\r\n",
        "  import torch.optim as optim\r\n",
        "\r\n",
        "  criterion = nn.BCELoss()\r\n",
        "  #optimizer = optim.Adam(model.parameters())\r\n",
        "  optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "  model = model.to(device)\r\n",
        "  criterion = criterion.to(device)\r\n",
        "\r\n",
        "  best_valid_loss = float('inf')\r\n",
        "  best_acc = float('inf')\r\n",
        "  best_train_loss = float('inf')\r\n",
        "  best_train_acc = float('inf')\r\n",
        "\r\n",
        "  for epoch in range(N_EPOCHS):\r\n",
        "      \r\n",
        "      #train the model\r\n",
        "      train_loss, train_acc = train_BCE(model, train_iterator, optimizer, criterion)\r\n",
        "      \r\n",
        "      #evaluate the model\r\n",
        "      valid_loss, valid_acc = evaluate_BCE(model, valid_iterator, criterion)\r\n",
        "      \r\n",
        "      #save the best model\r\n",
        "      if valid_loss < best_valid_loss:\r\n",
        "          best_valid_loss = valid_loss\r\n",
        "          best_acc = valid_acc\r\n",
        "          best_train_loss = train_loss\r\n",
        "          best_train_acc = train_acc\r\n",
        "          torch.save(model.state_dict(), 'final_allocine.pt')\r\n",
        "      \r\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "  \r\n",
        "  pd.DataFrame({\"filtre\" : largeur, \"btl\" : best_train_loss,\"bta\" : best_train_acc, \"bvl\" : best_valid_loss, \"bva\" : best_acc}, index = [0]).to_csv(dossier_donnees +  \"/resultat_larg_filtre.csv\", mode='a', header=False)  \r\n",
        "#sauvegarder les iterators"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ilm9XUWW_Od"
      },
      "source": [
        "# Plusieurs filtres autour de la largeur optimale (2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezfoXvq_XEx4",
        "outputId": "19e23af7-0e8b-4a02-e3f8-6a4a86e6437e"
      },
      "source": [
        "list_model = list(itertools.chain.from_iterable([list(combinations(range(1,5),i)) for i in range(1,5)]))\r\n",
        "N_EPOCHS = 30\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "pd.DataFrame({\"filtre\" : \"0\", \"btl\" : 0,\"bta\" : 0, \"bvl\" : 0, \"bva\" : 0}, index = [0]).to_csv(dossier_donnees + \"/resultat_larg_filtre_diff_type.csv\")\r\n",
        "\r\n",
        "for largeur in list_model:\r\n",
        "  model = classifier3F(text.vocab.vectors,SENTENCE_SIZE,vector_embedding.shape[1],400,largeur,2,0.5) #check the difference between syn0 and the other choice. \r\n",
        "  #I think it deals with negative sampling\r\n",
        "  print(model)\r\n",
        "  import torch.optim as optim\r\n",
        "\r\n",
        "  criterion = nn.BCELoss()\r\n",
        "  #optimizer = optim.Adam(model.parameters())\r\n",
        "  optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) #weight_decay : L2 penalisation !\r\n",
        "\r\n",
        "  model = model.to(device)\r\n",
        "  criterion = criterion.to(device)\r\n",
        "\r\n",
        "  best_valid_loss = float('inf')\r\n",
        "  best_acc = float('inf')\r\n",
        "  best_train_loss = float('inf')\r\n",
        "  best_train_acc = float('inf')\r\n",
        "\r\n",
        "  for epoch in range(N_EPOCHS):\r\n",
        "      \r\n",
        "      #train the model\r\n",
        "      train_loss, train_acc = train_BCE(model, train_iterator, optimizer, criterion)\r\n",
        "      \r\n",
        "      #evaluate the model\r\n",
        "      valid_loss, valid_acc = evaluate_BCE(model, valid_iterator, criterion)\r\n",
        "      \r\n",
        "      #save the best model\r\n",
        "      if valid_loss < best_valid_loss:\r\n",
        "          best_valid_loss = valid_loss\r\n",
        "          best_acc = valid_acc\r\n",
        "          best_train_loss = train_loss\r\n",
        "          best_train_acc = train_acc\r\n",
        "          #torch.save(model.state_dict(), 'final_allocine.pt')\r\n",
        "      \r\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "  \r\n",
        "  pd.DataFrame({\"filtre\" : str(largeur), \"btl\" : best_train_loss,\"bta\" : best_train_acc, \"bvl\" : best_valid_loss, \"bva\" : best_acc}, index = [0]).to_csv(dossier_donnees +  \"/resultat_larg_filtre_diff_type.csv\", mode='a', header=False)  \r\n",
        "#sauvegarder les iterators"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier3F(\n",
            "  (embedding): Embedding(49075, 200)\n",
            "  (conv): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(1, 400, kernel_size=(1, 200), stride=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): MaxPool2d(kernel_size=(67, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=400, out_features=2, bias=True)\n",
            "  (sm): Softmax(dim=1)\n",
            "  (dp): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "\tTrain Loss: 0.373 | Train Acc: 83.31%\n",
            "\t Val. Loss: 0.285 |  Val. Acc: 88.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-6g89kgYYo"
      },
      "source": [
        "## Lecture d'un modèle enregistré"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vne84b-dgezX"
      },
      "source": [
        "model = classifier3F(torch.from_numpy(vector_embedding),SENTENCE_SIZE,vector_embedding.shape[1],1000,(1,2),2,0.5) #check the difference between syn0 and the other choice. \r\n",
        "weights = model.load_state_dict(torch.load(dossier_donnees + \"/final_allocine.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWSj0gvJkMu6"
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "E03pQcD2gmBt",
        "outputId": "f96bea96-f107-4fba-c9e9-691814e8d0bc"
      },
      "source": [
        "pred = []\r\n",
        "\r\n",
        "for element in valid_iterator:\r\n",
        "    pred.append(model(element.t))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-4762f9545436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-73fbc07cce5c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[nb_batch, nb_channel = 1, nb_words_in_sentences, embedding_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-73fbc07cce5c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[nb_batch, nb_channel = 1, nb_words_in_sentences, embedding_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 14.73 GiB total capacity; 13.11 GiB already allocated; 3.88 MiB free; 13.78 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO8mHaZQjOH4",
        "outputId": "6029bee2-4174-46d4-f2f2-0356f9c1cc7f"
      },
      "source": [
        "torch.cat([pred,torch.tensor([2,3]),torch.tensor([2,3])], dim = -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 3., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}