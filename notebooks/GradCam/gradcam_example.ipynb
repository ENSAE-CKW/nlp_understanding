{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GradCAM example for 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wenceslas\\Documents\\cours\\ENSAE\\2A\\Normal\\statapp\\nlp_understanding\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()  # this points to 'notebooks/' folder\n",
    "proj_path = current_dir.parent.parent \n",
    "print(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import re\n",
    "from nltk.metrics import distance\n",
    "\n",
    "from deep_nlp.cnncharclassifier import CNNCharClassifier, charToTensor\n",
    "from src.deep_nlp.embed_cnn.embcnnmodel_gradcam import classifier3F\n",
    "from deep_nlp.bilstm_cnn.bilstmcnn_gradcam import BilstmCnn\n",
    "from deep_nlp.grad_cam.utils.letter import rebuild_text, prepare_heatmap, LetterToToken\n",
    "from deep_nlp.grad_cam.plot import plot_bar_heatmap, plot_text_and_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_text_and_heatmap(text= [\"ok\", \"salt\", \"ok\"]*2\n",
    "                      , heatmap= np.array([0, 1, 2]*2)\n",
    "                      , figsize= (10, 3)\n",
    "                      , fontsize_text= \"medium\"\n",
    "                      , cmap= \"Greens\" #if type_map == \"max\" else \"PiYG\"\n",
    "                      , word_or_letter= \"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "cnn_sequence_len= 1014\n",
    "cnn_feature_num= 87\n",
    "cnn_feature_size= 256\n",
    "cnn_kernel_one= 7\n",
    "cnn_kernel_two= 3\n",
    "cnn_stride_one= 1\n",
    "cnn_stride_two= 3\n",
    "cnn_output_linear= 1024\n",
    "cnn_num_class= 2\n",
    "cnn_dropout= 0.5\n",
    "cnn_cuda_allow= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_path_saved= \"data/06_models/cnn_char_classifier/cnn_char_model/cnn_char_model.pt\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + model_path_saved, 'rb') as f:\n",
    "    model_saved= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_df= pd.read_csv(str(proj_path)+ \"\\\\\" + \"data/01_raw/allocine_test.csv\")\n",
    "\n",
    "test_data= charToTensor(data_df= data_df, sentence_max_size= cnn_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "parameters = {\"sequence_len\": cnn_sequence_len, \"feature_num\": cnn_feature_num\n",
    "    , \"feature_size\": cnn_feature_size, \"kernel_one\": cnn_kernel_one\n",
    "    , \"kernel_two\": cnn_kernel_two, \"stride_one\": cnn_stride_one\n",
    "    , \"stride_two\": cnn_stride_two, \"output_linear\": cnn_output_linear\n",
    "    , \"num_class\": cnn_num_class, \"dropout\": cnn_dropout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CNNCharClassifier(**parameters)\n",
    "\n",
    "if cnn_cuda_allow:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.load_state_dict(model_saved)\n",
    "\n",
    "state_dict= model.module.state_dict() # delete module to allow cpu loading\n",
    "\n",
    "cpu_model= CNNCharClassifier(**parameters).cpu()\n",
    "cpu_model.load_state_dict(state_dict)\n",
    "\n",
    "cpu_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cpu_dict= cpu_model.state_dict()\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_object(model_cpu_dict, \"models/cnn_char_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "def cnn_char_gradcam(index, threshold= None,**kwargs):\n",
    "    \"\"\"\n",
    "    Display gradcam text with knowing the index text position\n",
    "    \n",
    "    -------\n",
    "    \n",
    "    kwargs:\n",
    "        - model\n",
    "        - loader : type charToTensor\n",
    "        - cnn_sequence_len\n",
    "        - params_graphics\n",
    "    \"\"\"\n",
    "    loader= kwargs[\"loader\"]\n",
    "    model= kwargs[\"model\"]\n",
    "    type_map= kwargs[\"type_map\"]\n",
    "    num_class= kwargs[\"num_class\"] \n",
    "    figsize= kwargs[\"figsize\"]\n",
    "    \n",
    "    text_sentence, _= loader[index]\n",
    "    text_sentence= torch.unsqueeze(text_sentence, 0)\n",
    "    \n",
    "    model.eval()\n",
    "    output= model(text_sentence)\n",
    "    print(\"Proba class 1 : {}\".format(torch.exp(output)[:, 1].data.numpy()[0]))\n",
    "    \n",
    "    heatmap_= model.get_heatmap(text= text_sentence\n",
    "                                    , num_class= num_class\n",
    "                                    , dim= [0, 2]\n",
    "                                    , type_map= type_map)\n",
    "    \n",
    "    # get the unique element\n",
    "    heatmap_values= heatmap_[-1]\n",
    "    \n",
    "    # CNNChar rebuilt from input the text\n",
    "    alphabet= loader.get_alphabet()+\" \"\n",
    "    rebuild_sentence= rebuild_text(text= text_sentence\n",
    "                                     , alphabet= alphabet\n",
    "                                     , space_index= len(alphabet) - 1 #83 # ajout de +4 si pas fait\n",
    "                                     , sequence_len= cnn_sequence_len)\n",
    "    \n",
    "    # Resize heatmap Brutal method\n",
    "    heatmap_match_sentence_size_invert= prepare_heatmap(heatmap= heatmap_values\n",
    "                                                    , text= rebuild_sentence)\n",
    "    \n",
    "    ## Transform character level to token one\n",
    "    letter_to_token= LetterToToken(text= rebuild_sentence\n",
    "                                   , heatmap= heatmap_match_sentence_size_invert)\n",
    "\n",
    "    results_dict= letter_to_token.transform_letter_to_token(type= \"tanh\")\n",
    "    tokens= results_dict[\"tokens\"]\n",
    "    heatmap_test= results_dict[\"heatmap\"]\n",
    "    \n",
    "    if threshold: # if inquired\n",
    "        condition= np.where(np.abs(heatmap_test) < threshold)[0] # if under, get index\n",
    "        heatmap_test[condition]= 0 # replace undervalues by 0\n",
    "    \n",
    "    plot_text_and_heatmap(text= tokens\n",
    "                      , heatmap= heatmap_test\n",
    "                      , figsize= figsize\n",
    "                      , fontsize_text= \"small\"\n",
    "                      , cmap= \"Greens\" if type_map == \"max\" else \"PiYG\"\n",
    "                      , word_or_letter= \"word\")\n",
    "    return heatmap_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "index= 14359 - 1\n",
    "num_class= 0\n",
    "figsize= (10, 4)\n",
    "# cnn_char_gradcam(index, model= cpu_model, loader= test_data, type_map= \"normalized_2\"\n",
    "#                  , num_class= num_class, figsize= figsize)\n",
    "cnn_char_gradcam(index, model= cpu_model, loader= test_data, type_map= \"max\"\n",
    "                 , num_class= num_class, figsize= figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator_cnn_embed_path= \"data/02_intermediate/test_iterator_cnn_embed.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + test_iterator_cnn_embed_path, 'rb') as f:\n",
    "    test_iterator_cnn_embed= pickle.load(f)\n",
    "    \n",
    "print(type(test_iterator_cnn_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "embed_for_torch_path= \"data/04_feature/w2v_torch.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + embed_for_torch_path, 'rb') as f:\n",
    "    embed_for_torch= pickle.load(f)\n",
    "    \n",
    "print(type(embed_for_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ind_dict_path= \"data/04_feature/voc.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + word_ind_dict_path, 'rb') as f:\n",
    "    word_ind_dict= pickle.load(f)\n",
    "    \n",
    "print(type(word_ind_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "# params_models = {\"wv\": embed_for_torch,\"no_words\": 67,\"embedding_dim\":200, \"nb_filter\":200\n",
    "#                  , \"height_filter\":tuple([1, 2, 3, 4, 5]), \"output_dim\":2, \"dropout\":0.8, \"padded\":True}\n",
    "\n",
    "params_models = {\"wv\": embed_for_torch,\"no_words\": 67,\"embedding_dim\":200, \"nb_filter\":600\n",
    "                 , \"height_filter\":tuple([1, 2]), \"output_dim\":2, \"dropout\":0.6, \"padded\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dict\n",
    "embed_cnn_model_for_save_path= \"data/06_models/embed_cnn/embed_cnn_classifier/embed_cnn.pt\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + embed_cnn_model_for_save_path, 'rb') as f:\n",
    "    embed_cnn_model_for_save= pickle.load(f)\n",
    "    \n",
    "print(type(embed_cnn_model_for_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embed = classifier3F(**params_models)\n",
    "\n",
    "model_embed.load_state_dict(embed_cnn_model_for_save)\n",
    "model_embed= model_embed.cpu()\n",
    "model_embed.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(model_embed.state_dict(), \"models/embed_cnn_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download fr_core_news_md\n",
    "import spacy\n",
    "nlp= spacy.load(\"fr_core_news_sm\",  disable=[\"tagger\", \"parser\",\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "import unicodedata\n",
    "\n",
    "def split_sentence(token: str, pattern_token_split= r'[\\s\\.\\,\\:\\;\\(\\)\\[\\]\\&\\!\\?\\/\\\\]+'):\n",
    "    return re.split(pattern_token_split, token)\n",
    "\n",
    "def clean_tokens(token: str, pattern= r'[\\s\\.\\,\\:\\;\\\"\\'\\(\\)\\[\\]\\&\\!\\?\\/\\\\]+'):\n",
    "    cleaned_token= re.sub(pattern, \"\", token)\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', cleaned_token)\n",
    "                        if unicodedata.category(c) != 'Mn').lower()\n",
    "\n",
    "def fast_lemm_token(token):\n",
    "    if token != \"\":\n",
    "        return [i.lemma_ for i in nlp(clean_tokens(token))][0]\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def compute_index_max_distance_jako(selected_word, tokenized_sentence, safe_threshold= 0.2\n",
    "                                    , sentence_length_wihout_clean= 120):\n",
    "    \"\"\"\n",
    "    jaro_winkler_sim = jaro_sim + ( l * p * (1 - jaro_sim) )\n",
    "    jaro_sim = 0 if m = 0 else 1/3 * (m/|s_1| + m/s_2 + (m-t)/m)\n",
    "\n",
    "    where:\n",
    "        - |s_i| is the length of string s_i\n",
    "        - m is the no. of matching characters\n",
    "        - t is the half no. of possible transpositions.\n",
    "    \"\"\"\n",
    "    stock_all_word_dist= []\n",
    "    last_up= 0\n",
    "    tokenized_sentence= tokenized_sentence[:sentence_length_wihout_clean] # sentence length, to ensure it is not looking for\n",
    "    # not implemented words (more than 67 because 67 was after cleaning, stop word and lemme)\n",
    "    for input_word in selected_word:\n",
    "        stock_input_word_dist= []\n",
    "\n",
    "        d= [distance.jaro_winkler_similarity(fast_lemm_token(input_word), fast_lemm_token(input_initial))\n",
    "           for input_initial in tokenized_sentence]\n",
    "        # safety threshold, if under stop the processus for the token\n",
    "        if max(d) <= safe_threshold:\n",
    "            continue\n",
    "        else: \n",
    "            tokenized_sentence= tokenized_sentence[np.argmax(d):]\n",
    "            last_up= np.argmax(d) + last_up # we cut the tokenized list, so we remember where was the\n",
    "        # last highest value in index\n",
    "        stock_all_word_dist.append(last_up)\n",
    "    return np.array(stock_all_word_dist)\n",
    "\n",
    "\n",
    "def embed_gradcam(index, heatmap_index, index_nothing= None, model_type= None\n",
    "                  , threshold= None, figsize_second= (10, 4), fontsize_text_second= \"small\" \n",
    "                  , threshold_second= 10, **kwargs):\n",
    "    \"\"\"\n",
    "    Display gradcam text with knowing the index text position\n",
    "    \n",
    "    -------\n",
    "    \n",
    "    kwargs:\n",
    "        - model\n",
    "        - loader : type charToTensor\n",
    "        - cnn_sequence_len\n",
    "        - params_graphics\n",
    "    \"\"\"\n",
    "    data_loader= kwargs[\"data_loader\"]\n",
    "    model= kwargs[\"model\"]\n",
    "    type_map= kwargs[\"type_map\"]\n",
    "    num_class= kwargs[\"num_class\"] \n",
    "    figsize= kwargs[\"figsize\"]\n",
    "    vocab= kwargs[\"vocab\"]\n",
    "    initial_review= kwargs[\"initial_review\"]\n",
    "    \n",
    "    text_sentence, _= next(itertools.islice(data_loader, index, None))\n",
    "    if model_type == \"bilstm\":\n",
    "        text_sentence= text_sentence.to(torch.int64)\n",
    "    \n",
    "    model.eval()\n",
    "    output= torch.exp(model(text_sentence))\n",
    "    print(\"Proba class 1 : {}\".format(output[:, 1].data.numpy()[0]))\n",
    "    \n",
    "    heatmap_= model.get_heatmap(text= text_sentence\n",
    "                                    , num_class= num_class\n",
    "                                    , dim= [0, 2]\n",
    "                                    , type_map= type_map)\n",
    "    heatmap_values= heatmap_[heatmap_index]\n",
    "    \n",
    "    text_index = text_sentence.squeeze().numpy()\n",
    "    vocab_reverse= {y:x for x,y in vocab.items()}\n",
    "    word = np.array([vocab_reverse.get(index, \"\") for index in text_index])\n",
    "    \n",
    "    if index_nothing is None: # generate warning but its ok dude\n",
    "        index_nothing = np.array([])\n",
    "    selected_word_bool = np.in1d(text_index, index_nothing)\n",
    "    # Get index of word we want\n",
    "    selected_word_index = np.where((~selected_word_bool)|(word != \"\"))[0]\n",
    "    # Select interesting words\n",
    "    selected_word = word#word[selected_word_index]\n",
    "    selected_heatmap_values= heatmap_values#[selected_word_index]\n",
    "    \n",
    "    if threshold: # if inquired\n",
    "        condition= np.where(np.abs(selected_heatmap_values) < threshold)[0] # if under, get index\n",
    "        selected_heatmap_values[condition]= 0 # replace undervalues by 0\n",
    "\n",
    "    # Token heatmap\n",
    "    plot_text_and_heatmap(text= selected_word.tolist()\n",
    "                      , heatmap= selected_heatmap_values\n",
    "                      , figsize= figsize\n",
    "                      , fontsize_text= \"small\"\n",
    "                      , cmap= \"Greens\" if type_map == \"max\" else \"PiYG\"\n",
    "                      , word_or_letter= \"word\")\n",
    "#     print(selected_heatmap_values)\n",
    "#     # Good token heatmap\n",
    "#     tokenized_sentence= split_sentence(initial_review)\n",
    "    \n",
    "#     # Compute token distance between initial sentence token\n",
    "#     stock_all_word_max_dist_id= compute_index_max_distance_jako(selected_word, tokenized_sentence)\n",
    "# #     simi_tokens= np.argmax(stock_all_word_dist, axis= 1) \n",
    "#     based_heatmap= np.zeros(len(tokenized_sentence))\n",
    "\n",
    "#     based_heatmap[stock_all_word_max_dist_id]= selected_heatmap_values[:stock_all_word_max_dist_id.shape[0]]\n",
    "    \n",
    "#     plot_text_and_heatmap(text= tokenized_sentence\n",
    "#                       , heatmap= based_heatmap\n",
    "#                       , figsize= figsize_second\n",
    "#                       , fontsize_text= fontsize_text_second\n",
    "#                       , cmap= \"PiYG\" if type_map == \"max\" else \"Greens\"\n",
    "#                       , threshold= threshold_second\n",
    "#                       , word_or_letter= \"word\")\n",
    "    \n",
    "    return selected_word, selected_heatmap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index= 16237 - 1\n",
    "num_class= 0\n",
    "heatmap_index= -1\n",
    "figsize= (10, 4)\n",
    "index_nothing= np.array([155563, 155562])\n",
    "\n",
    "data_review_test= pd.read_csv(\"../GradCam/all_model_prediction.csv\")\n",
    "initial_review_tt= data_review_test[\"review\"].values\n",
    "\n",
    "initial_review= initial_review_tt[index]\n",
    "\n",
    "selected_word, selected_heatmap_values= embed_gradcam(index, heatmap_index= heatmap_index\n",
    "                                                      , model= model_embed\n",
    "                                                      , data_loader= test_iterator_cnn_embed\n",
    "                                                      , type_map= \"max\", vocab= word_ind_dict\n",
    "                                                      , num_class= num_class, figsize= figsize\n",
    "                                                      , index_nothing= index_nothing\n",
    "                                                      , initial_review= initial_review\n",
    "                                                      , figsize_second= (10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "embed_matrix_path= \"data/02_intermediate/bilstm_cnn/embed_matrix.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + embed_matrix_path, 'rb') as f:\n",
    "    embed_matrix= pickle.load(f)\n",
    "    \n",
    "print(type(embed_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ind_dict_path_bilstm= \"data/04_feature/voc_bilstm.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + word_ind_dict_path_bilstm, 'rb') as f:\n",
    "    word_ind_dict_bilstm= pickle.load(f)\n",
    "    \n",
    "print(type(word_ind_dict_bilstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "test_batch_bilstm_path= \"data/02_intermediate/test_iterator_cnn_bilstm.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + test_batch_bilstm_path, 'rb') as f:\n",
    "    test_batch_bilstm= pickle.load(f)\n",
    "    \n",
    "print(type(test_batch_bilstm))#BiLSTM + CNN\n",
    "num_epochs=  50\n",
    "batch_size= 32\n",
    "patience= 5\n",
    "lr= 0.001\n",
    "input_dim= 200\n",
    "hidden_dim= 128\n",
    "layer_dim= 2\n",
    "feature_size= 256\n",
    "output_dim= 2\n",
    "kernel_size= 3\n",
    "dropout_rate= 0.5\n",
    "sentence_size= 67\n",
    "padded= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "bilstm_cnn_model_for_save_path= \"data/06_models/bilstm_cnn/bilstm_cnn_classifier/bilstm_cnn.pt\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + bilstm_cnn_model_for_save_path, 'rb') as f:\n",
    "    bilstm_cnn_model_for_save= pickle.load(f)\n",
    "    \n",
    "print(type(bilstm_cnn_model_for_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BilstmCnn(embed_matrix, sentence_size, input_dim, hidden_dim\n",
    "                  , layer_dim, output_dim, feature_size, kernel_size, dropout_rate, padded)\n",
    "\n",
    "if cnn_cuda_allow:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.load_state_dict(bilstm_cnn_model_for_save)\n",
    "\n",
    "state_dict= model.module.state_dict() \n",
    "\n",
    "cpu_bilstm_model= BilstmCnn(embed_matrix, sentence_size, input_dim, hidden_dim\n",
    "                  , layer_dim, output_dim, feature_size, kernel_size, dropout_rate, padded).cpu()\n",
    "\n",
    "cpu_bilstm_model.load_state_dict(state_dict)\n",
    "cpu_bilstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(cpu_bilstm_model.state_dict(), \"models/bilstm_cnn_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index= 1- 1\n",
    "num_class= 0\n",
    "figsize= (10, 4)\n",
    "index_nothing= np.array([144213])\n",
    "\n",
    "data_review_test= pd.read_csv(\"../GradCam/all_model_prediction.csv\")\n",
    "initial_review_tt= data_review_test[\"review\"].values\n",
    "\n",
    "initial_review= initial_review_tt[index]\n",
    "\n",
    "selected_word, selected_heatmap_values= embed_gradcam(index, heatmap_index= -1, model_type= \"bilstm\"\n",
    "                                                      , model= cpu_bilstm_model\n",
    "                                                      , data_loader= test_batch_bilstm\n",
    "                                                      , type_map= \"max\"\n",
    "                                                      , vocab= word_ind_dict_bilstm\n",
    "                                                      , num_class= num_class, figsize= figsize\n",
    "                                                      , index_nothing= index_nothing\n",
    "                                                      , initial_review= initial_review\n",
    "                                                      , figsize_second= (10, 10))\n",
    "selected_heatmap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print all local interpretability for GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_print= np.array([14359, 16238, 7399, 18593, 17478, 1635, 8273, 17546, 5412, 8464, 12148, 4764\n",
    "                 , 4629, 19019, 8670, 12221, 7087, 13267, 18238])\n",
    "label_data= np.array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n",
    "\n",
    "index_to_print -= 1\n",
    "\n",
    "index= 14359 - 1\n",
    "num_class= 1\n",
    "figsize= (10, 4)\n",
    "index_nothing_bilstm= np.array([144213])\n",
    "index_nothing_vanilla= np.array([155563, 155562])\n",
    "\n",
    "\n",
    "data_review_test= pd.read_csv(\"../GradCam/all_model_prediction.csv\")\n",
    "initial_review_tt= data_review_test[\"review\"].values\n",
    "\n",
    "initial_review= initial_review_tt[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_model_interpretability(index, m= \"max\", threshold= None, num_class= 1, heatmap_index= 1):\n",
    "    # CNN Character level\n",
    "    print(\"CNN Character level\")\n",
    "    h_c= cnn_char_gradcam(index, threshold= threshold, model= cpu_model, loader= test_data\n",
    "                     , type_map= m, num_class= num_class, figsize= figsize)\n",
    "    \n",
    "    # Vanilla Embed\n",
    "    print(\"Embed CNN\")\n",
    "    _, h_em= embed_gradcam(index, heatmap_index= heatmap_index, model= model_embed, threshold= threshold\n",
    "                                                      , data_loader= test_iterator_cnn_embed\n",
    "                                                      , type_map= m, vocab= word_ind_dict\n",
    "                                                      , num_class= num_class, figsize= figsize\n",
    "                                                      , index_nothing= index_nothing\n",
    "                                                      , initial_review= initial_review\n",
    "                                                      , figsize_second= (10, 10))\n",
    "    \n",
    "    # BILSTM Embed\n",
    "    print(\"BILSTM CNN\")\n",
    "    _, h_bi= embed_gradcam(index, heatmap_index= -1, model_type= \"bilstm\", threshold= threshold\n",
    "                                                      , model= cpu_bilstm_model\n",
    "                                                      , data_loader= test_batch_bilstm\n",
    "                                                      , type_map= m\n",
    "                                                      , vocab= word_ind_dict_bilstm\n",
    "                                                      , num_class= num_class, figsize= figsize\n",
    "                                                      , index_nothing= index_nothing\n",
    "                                                      , initial_review= initial_review\n",
    "                                                      , figsize_second= (10, 10))\n",
    "    return h_c, h_em, h_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# without threshold\n",
    "for i in range(index_to_print.shape[0]):\n",
    "    index= index_to_print[i]\n",
    "    print(\"\\n\")\n",
    "    print(index)\n",
    "    print(\"True label : {}\".format(label_data[i]))\n",
    "    print(\"\\n\")\n",
    "    initial_review= initial_review_tt[index]\n",
    "    print(initial_review)\n",
    "    print(\"\\n\")\n",
    "    print_all_model_interpretability(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with threshold\n",
    "for i in range(index_to_print.shape[0]):\n",
    "    index= index_to_print[i]\n",
    "    print(\"\\n\")\n",
    "    print(index)\n",
    "    print(\"True label : {}\".format(label_data[i]))\n",
    "    print(\"\\n\")\n",
    "    initial_review= initial_review_tt[index]\n",
    "    print(initial_review)\n",
    "    print(\"\\n\")\n",
    "    print_all_model_interpretability(index)#, threshold= 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index= 6177 #-1\n",
    "heatmap_index= -1\n",
    "num_class= 1\n",
    "print(\"\\n\")\n",
    "print(index)\n",
    "# print(\"True label : {}\".format(label_data[i]))\n",
    "print(\"\\n\")\n",
    "initial_review= initial_review_tt[index]\n",
    "print(initial_review)\n",
    "print(\"\\n\")\n",
    "print_all_model_interpretability(index, threshold= 0.75, num_class= num_class\n",
    "                                 , heatmap_index= heatmap_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text_and_heatmap(text= [\"ok\", \"salt\", \"ok\"]*3\n",
    "                      , heatmap= np.array([0, 1, 2]*3)\n",
    "                      , figsize= figsize\n",
    "                      , fontsize_text= \"medium\"\n",
    "                      , cmap= \"Greens\" #if type_map == \"max\" else \"PiYG\"\n",
    "                      , word_or_letter= \"word\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
