{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GradCAM example for 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()  # this points to 'notebooks/' folder\n",
    "proj_path = current_dir.parent.parent \n",
    "print(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import re\n",
    "from nltk.metrics import distance\n",
    "\n",
    "from deep_nlp.cnncharclassifier import CNNCharClassifier, charToTensor\n",
    "from src.deep_nlp.embed_cnn.embcnnmodel_gradcam import classifier3F\n",
    "from deep_nlp.bilstm_cnn.bilstmcnn_gradcam import BilstmCnn\n",
    "from deep_nlp.grad_cam.utils.letter import rebuild_text, prepare_heatmap, LetterToToken\n",
    "from deep_nlp.grad_cam.plot import plot_bar_heatmap, plot_text_and_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "cnn_sequence_len= 1014\n",
    "cnn_feature_num= 87\n",
    "cnn_feature_size= 256\n",
    "cnn_kernel_one= 7\n",
    "cnn_kernel_two= 3\n",
    "cnn_stride_one= 1\n",
    "cnn_stride_two= 3\n",
    "cnn_output_linear= 1024\n",
    "cnn_num_class= 2\n",
    "cnn_dropout= 0.5\n",
    "cnn_cuda_allow= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_path_saved= \"data/06_models/cnn_char_classifier/cnn_char_model/cnn_char_model.pt\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + model_path_saved, 'rb') as f:\n",
    "    model_saved= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_df= pd.read_csv(str(proj_path)+ \"\\\\\" + \"data/01_raw/allocine_test.csv\")\n",
    "\n",
    "test_data= charToTensor(data_df= data_df, sentence_max_size= cnn_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "parameters = {\"sequence_len\": cnn_sequence_len, \"feature_num\": cnn_feature_num\n",
    "    , \"feature_size\": cnn_feature_size, \"kernel_one\": cnn_kernel_one\n",
    "    , \"kernel_two\": cnn_kernel_two, \"stride_one\": cnn_stride_one\n",
    "    , \"stride_two\": cnn_stride_two, \"output_linear\": cnn_output_linear\n",
    "    , \"num_class\": cnn_num_class, \"dropout\": cnn_dropout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CNNCharClassifier(**parameters)\n",
    "\n",
    "if cnn_cuda_allow:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.load_state_dict(model_saved)\n",
    "\n",
    "state_dict= model.module.state_dict() # delete module to allow cpu loading\n",
    "\n",
    "cpu_model= CNNCharClassifier(**parameters).cpu()\n",
    "cpu_model.load_state_dict(state_dict)\n",
    "\n",
    "cpu_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cpu_dict= cpu_model.state_dict()\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save_object(model_cpu_dict, \"models/cnn_char_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "def cnn_char_gradcam(index, threshold= None,**kwargs):\n",
    "    \"\"\"\n",
    "    Display gradcam text with knowing the index text position\n",
    "    \n",
    "    -------\n",
    "    \n",
    "    kwargs:\n",
    "        - model\n",
    "        - loader : type charToTensor\n",
    "        - cnn_sequence_len\n",
    "        - params_graphics\n",
    "    \"\"\"\n",
    "    loader= kwargs[\"loader\"]\n",
    "    model= kwargs[\"model\"]\n",
    "    type_map= kwargs[\"type_map\"]\n",
    "    num_class= kwargs[\"num_class\"] \n",
    "    figsize= kwargs[\"figsize\"]\n",
    "    \n",
    "    text_sentence, _= loader[index]\n",
    "    text_sentence= torch.unsqueeze(text_sentence, 0)\n",
    "    \n",
    "    model.eval()\n",
    "    output= model(text_sentence)\n",
    "    print(\"Proba class 1 : {}\".format(torch.exp(output)[:, 1].data.numpy()[0]))\n",
    "    \n",
    "    heatmap_= model.get_heatmap(text= text_sentence\n",
    "                                    , num_class= num_class\n",
    "                                    , dim= [0, 2]\n",
    "                                    , type_map= type_map)\n",
    "    \n",
    "    # get the unique element\n",
    "    heatmap_values= heatmap_[-1]\n",
    "    \n",
    "    # CNNChar rebuilt from input the text\n",
    "    alphabet= loader.get_alphabet()+\" \"\n",
    "    rebuild_sentence= rebuild_text(text= text_sentence\n",
    "                                     , alphabet= alphabet\n",
    "                                     , space_index= len(alphabet) - 1 #83 # ajout de +4 si pas fait\n",
    "                                     , sequence_len= cnn_sequence_len)\n",
    "    \n",
    "    # Resize heatmap Brutal method\n",
    "    heatmap_match_sentence_size_invert= prepare_heatmap(heatmap= heatmap_values\n",
    "                                                    , text= rebuild_sentence)\n",
    "    \n",
    "    ## Transform character level to token one\n",
    "    letter_to_token= LetterToToken(text= rebuild_sentence\n",
    "                                   , heatmap= heatmap_match_sentence_size_invert)\n",
    "\n",
    "    results_dict= letter_to_token.transform_letter_to_token(type= \"tanh\")\n",
    "    tokens= results_dict[\"tokens\"]\n",
    "    heatmap_test= results_dict[\"heatmap\"]\n",
    "    \n",
    "    if threshold: # if inquired\n",
    "        condition= np.where(np.abs(heatmap_test) < threshold)[0] # if under, get index\n",
    "        heatmap_test[condition]= 0 # replace undervalues by 0\n",
    "    \n",
    "    plot_text_and_heatmap(text= tokens\n",
    "                      , heatmap= heatmap_test\n",
    "                      , figsize= figsize\n",
    "                      , fontsize_text= \"small\"\n",
    "                      , cmap= \"Greens\" if type_map == \"max\" else \"PiYG\"\n",
    "                      , word_or_letter= \"word\")\n",
    "    return heatmap_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "index= 14359 - 1\n",
    "num_class= 0\n",
    "figsize= (10, 4)\n",
    "# cnn_char_gradcam(index, model= cpu_model, loader= test_data, type_map= \"normalized_2\"\n",
    "#                  , num_class= num_class, figsize= figsize)\n",
    "cnn_char_gradcam(index, model= cpu_model, loader= test_data, type_map= \"max\"\n",
    "                 , num_class= num_class, figsize= figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator_cnn_embed_path= \"data/02_intermediate/test_iterator_cnn_embed.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + test_iterator_cnn_embed_path, 'rb') as f:\n",
    "    test_iterator_cnn_embed= pickle.load(f)\n",
    "    \n",
    "print(type(test_iterator_cnn_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "embed_for_torch_path= \"data/04_feature/w2v_torch.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + embed_for_torch_path, 'rb') as f:\n",
    "    embed_for_torch= pickle.load(f)\n",
    "    \n",
    "print(type(embed_for_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ind_dict_path= \"data/04_feature/voc.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + word_ind_dict_path, 'rb') as f:\n",
    "    word_ind_dict= pickle.load(f)\n",
    "    \n",
    "print(type(word_ind_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "# params_models = {\"wv\": embed_for_torch,\"no_words\": 67,\"embedding_dim\":200, \"nb_filter\":200\n",
    "#                  , \"height_filter\":tuple([1, 2, 3, 4, 5]), \"output_dim\":2, \"dropout\":0.8, \"padded\":True}\n",
    "\n",
    "params_models = {\"wv\": embed_for_torch,\"no_words\": 67,\"embedding_dim\":200, \"nb_filter\":600\n",
    "                 , \"height_filter\":tuple([1, 2]), \"output_dim\":2, \"dropout\":0.6, \"padded\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dict\n",
    "embed_cnn_model_for_save_path= \"data/06_models/embed_cnn/embed_cnn_classifier/embed_cnn.pt\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + embed_cnn_model_for_save_path, 'rb') as f:\n",
    "    embed_cnn_model_for_save= pickle.load(f)\n",
    "    \n",
    "print(type(embed_cnn_model_for_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embed = classifier3F(**params_models)\n",
    "\n",
    "model_embed.load_state_dict(embed_cnn_model_for_save)\n",
    "model_embed= model_embed.cpu()\n",
    "model_embed.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(model_embed.state_dict(), \"models/embed_cnn_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download fr_core_news_md\n",
    "import spacy\n",
    "nlp= spacy.load(\"fr_core_news_sm\",  disable=[\"tagger\", \"parser\",\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "import unicodedata\n",
    "\n",
    "def split_sentence(token: str, pattern_token_split= r'[\\s\\.\\,\\:\\;\\(\\)\\[\\]\\&\\!\\?\\/\\\\]+'):\n",
    "    return re.split(pattern_token_split, token)\n",
    "\n",
    "def clean_tokens(token: str, pattern= r'[\\s\\.\\,\\:\\;\\\"\\'\\(\\)\\[\\]\\&\\!\\?\\/\\\\]+'):\n",
    "    cleaned_token= re.sub(pattern, \"\", token)\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', cleaned_token)\n",
    "                        if unicodedata.category(c) != 'Mn').lower()\n",
    "\n",
    "def fast_lemm_token(token):\n",
    "    if token != \"\":\n",
    "        return [i.lemma_ for i in nlp(clean_tokens(token))][0]\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def compute_index_max_distance_jako(selected_word, tokenized_sentence, safe_threshold= 0.2\n",
    "                                    , sentence_length_wihout_clean= 120):\n",
    "    \"\"\"\n",
    "    jaro_winkler_sim = jaro_sim + ( l * p * (1 - jaro_sim) )\n",
    "    jaro_sim = 0 if m = 0 else 1/3 * (m/|s_1| + m/s_2 + (m-t)/m)\n",
    "\n",
    "    where:\n",
    "        - |s_i| is the length of string s_i\n",
    "        - m is the no. of matching characters\n",
    "        - t is the half no. of possible transpositions.\n",
    "    \"\"\"\n",
    "    stock_all_word_dist= []\n",
    "    last_up= 0\n",
    "    tokenized_sentence= tokenized_sentence[:sentence_length_wihout_clean] # sentence length, to ensure it is not looking for\n",
    "    # not implemented words (more than 67 because 67 was after cleaning, stop word and lemme)\n",
    "    for input_word in selected_word:\n",
    "        stock_input_word_dist= []\n",
    "\n",
    "        d= [distance.jaro_winkler_similarity(fast_lemm_token(input_word), fast_lemm_token(input_initial))\n",
    "           for input_initial in tokenized_sentence]\n",
    "        # safety threshold, if under stop the processus for the token\n",
    "        if max(d) <= safe_threshold:\n",
    "            continue\n",
    "        else: \n",
    "            tokenized_sentence= tokenized_sentence[np.argmax(d):]\n",
    "            last_up= np.argmax(d) + last_up # we cut the tokenized list, so we remember where was the\n",
    "        # last highest value in index\n",
    "        stock_all_word_dist.append(last_up)\n",
    "    return np.array(stock_all_word_dist)\n",
    "\n",
    "\n",
    "def embed_gradcam(index, heatmap_index, index_nothing= None, model_type= None\n",
    "                  , threshold= None, figsize_second= (10, 4), fontsize_text_second= \"small\" \n",
    "                  , threshold_second= 10, **kwargs):\n",
    "    \"\"\"\n",
    "    Display gradcam text with knowing the index text position\n",
    "    \n",
    "    -------\n",
    "    \n",
    "    kwargs:\n",
    "        - model\n",
    "        - loader : type charToTensor\n",
    "        - cnn_sequence_len\n",
    "        - params_graphics\n",
    "    \"\"\"\n",
    "    data_loader= kwargs[\"data_loader\"]\n",
    "    model= kwargs[\"model\"]\n",
    "    type_map= kwargs[\"type_map\"]\n",
    "    num_class= kwargs[\"num_class\"] \n",
    "    figsize= kwargs[\"figsize\"]\n",
    "    vocab= kwargs[\"vocab\"]\n",
    "    initial_review= kwargs[\"initial_review\"]\n",
    "    \n",
    "    text_sentence, _= next(itertools.islice(data_loader, index, None))\n",
    "    if model_type == \"bilstm\":\n",
    "        text_sentence= text_sentence.to(torch.int64)\n",
    "    \n",
    "    model.eval()\n",
    "    output= torch.exp(model(text_sentence))\n",
    "    print(\"Proba class 1 : {}\".format(output[:, 1].data.numpy()[0]))\n",
    "    \n",
    "    heatmap_= model.get_heatmap(text= text_sentence\n",
    "                                    , num_class= num_class\n",
    "                                    , dim= [0, 2]\n",
    "                                    , type_map= type_map)\n",
    "    heatmap_values= heatmap_[heatmap_index]\n",
    "    \n",
    "    text_index = text_sentence.squeeze().numpy()\n",
    "    vocab_reverse= {y:x for x,y in vocab.items()}\n",
    "    word = np.array([vocab_reverse.get(index, \"\") for index in text_index])\n",
    "    \n",
    "    if index_nothing is None: # generate warning but its ok dude\n",
    "        index_nothing = np.array([])\n",
    "    selected_word_bool = np.in1d(text_index, index_nothing)\n",
    "    # Get index of word we want\n",
    "    selected_word_index = np.where((~selected_word_bool)|(word != \"\"))[0]\n",
    "    # Select interesting words\n",
    "    selected_word = word#word[selected_word_index]\n",
    "    selected_heatmap_values= heatmap_values#[selected_word_index]\n",
    "    \n",
    "    if threshold: # if inquired\n",
    "        condition= np.where(np.abs(selected_heatmap_values) < threshold)[0] # if under, get index\n",
    "        selected_heatmap_values[condition]= 0 # replace undervalues by 0\n",
    "\n",
    "    # Token heatmap\n",
    "    plot_text_and_heatmap(text= selected_word.tolist()\n",
    "                      , heatmap= selected_heatmap_values\n",
    "                      , figsize= figsize\n",
    "                      , fontsize_text= \"small\"\n",
    "                      , cmap= \"Greens\" if type_map == \"max\" else \"PiYG\"\n",
    "                      , word_or_letter= \"word\")\n",
    "#     print(selected_heatmap_values)\n",
    "#     # Good token heatmap\n",
    "#     tokenized_sentence= split_sentence(initial_review)\n",
    "    \n",
    "#     # Compute token distance between initial sentence token\n",
    "#     stock_all_word_max_dist_id= compute_index_max_distance_jako(selected_word, tokenized_sentence)\n",
    "# #     simi_tokens= np.argmax(stock_all_word_dist, axis= 1) \n",
    "#     based_heatmap= np.zeros(len(tokenized_sentence))\n",
    "\n",
    "#     based_heatmap[stock_all_word_max_dist_id]= selected_heatmap_values[:stock_all_word_max_dist_id.shape[0]]\n",
    "    \n",
    "#     plot_text_and_heatmap(text= tokenized_sentence\n",
    "#                       , heatmap= based_heatmap\n",
    "#                       , figsize= figsize_second\n",
    "#                       , fontsize_text= fontsize_text_second\n",
    "#                       , cmap= \"PiYG\" if type_map == \"max\" else \"Greens\"\n",
    "#                       , threshold= threshold_second\n",
    "#                       , word_or_letter= \"word\")\n",
    "    \n",
    "    return selected_word, selected_heatmap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index= 16237 - 1\n",
    "num_class= 0\n",
    "heatmap_index= -1\n",
    "figsize= (10, 4)\n",
    "index_nothing= np.array([155563, 155562])\n",
    "\n",
    "data_review_test= pd.read_csv(\"../GradCam/all_model_prediction.csv\")\n",
    "initial_review_tt= data_review_test[\"review\"].values\n",
    "\n",
    "initial_review= initial_review_tt[index]\n",
    "\n",
    "selected_word, selected_heatmap_values= embed_gradcam(index, heatmap_index= heatmap_index\n",
    "                                                      , model= model_embed\n",
    "                                                      , data_loader= test_iterator_cnn_embed\n",
    "                                                      , type_map= \"max\", vocab= word_ind_dict\n",
    "                                                      , num_class= num_class, figsize= figsize\n",
    "                                                      , index_nothing= index_nothing\n",
    "                                                      , initial_review= initial_review\n",
    "                                                      , figsize_second= (10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "embed_matrix_path= \"data/02_intermediate/bilstm_cnn/embed_matrix.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + embed_matrix_path, 'rb') as f:\n",
    "    embed_matrix= pickle.load(f)\n",
    "    \n",
    "print(type(embed_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ind_dict_path_bilstm= \"data/04_feature/voc_bilstm.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + word_ind_dict_path_bilstm, 'rb') as f:\n",
    "    word_ind_dict_bilstm= pickle.load(f)\n",
    "    \n",
    "print(type(word_ind_dict_bilstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "test_batch_bilstm_path= \"data/02_intermediate/test_iterator_cnn_bilstm.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + test_batch_bilstm_path, 'rb') as f:\n",
    "    test_batch_bilstm= pickle.load(f)\n",
    "    \n",
    "print(type(test_batch_bilstm))#BiLSTM + CNN\n",
    "num_epochs=  50\n",
    "batch_size= 32\n",
    "patience= 5\n",
    "lr= 0.001\n",
    "input_dim= 200\n",
    "hidden_dim= 128\n",
    "layer_dim= 2\n",
    "feature_size= 256\n",
    "output_dim= 2\n",
    "kernel_size= 3\n",
    "dropout_rate= 0.5\n",
    "sentence_size= 67\n",
    "padded= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "bilstm_cnn_model_for_save_path= \"data/06_models/bilstm_cnn/bilstm_cnn_classifier/bilstm_cnn.pt\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + bilstm_cnn_model_for_save_path, 'rb') as f:\n",
    "    bilstm_cnn_model_for_save= pickle.load(f)\n",
    "    \n",
    "print(type(bilstm_cnn_model_for_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BilstmCnn(embed_matrix, sentence_size, input_dim, hidden_dim\n",
    "                  , layer_dim, output_dim, feature_size, kernel_size, dropout_rate, padded)\n",
    "\n",
    "if cnn_cuda_allow:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.load_state_dict(bilstm_cnn_model_for_save)\n",
    "\n",
    "state_dict= model.module.state_dict() \n",
    "\n",
    "cpu_bilstm_model= BilstmCnn(embed_matrix, sentence_size, input_dim, hidden_dim\n",
    "                  , layer_dim, output_dim, feature_size, kernel_size, dropout_rate, padded).cpu()\n",
    "\n",
    "cpu_bilstm_model.load_state_dict(state_dict)\n",
    "cpu_bilstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(cpu_bilstm_model.state_dict(), \"models/bilstm_cnn_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index= 1- 1\n",
    "num_class= 0\n",
    "figsize= (10, 4)\n",
    "index_nothing= np.array([144213])\n",
    "\n",
    "data_review_test= pd.read_csv(\"../GradCam/all_model_prediction.csv\")\n",
    "initial_review_tt= data_review_test[\"review\"].values\n",
    "\n",
    "initial_review= initial_review_tt[index]\n",
    "\n",
    "selected_word, selected_heatmap_values= embed_gradcam(index, heatmap_index= -1, model_type= \"bilstm\"\n",
    "                                                      , model= cpu_bilstm_model\n",
    "                                                      , data_loader= test_batch_bilstm\n",
    "                                                      , type_map= \"max\"\n",
    "                                                      , vocab= word_ind_dict_bilstm\n",
    "                                                      , num_class= num_class, figsize= figsize\n",
    "                                                      , index_nothing= index_nothing\n",
    "                                                      , initial_review= initial_review\n",
    "                                                      , figsize_second= (10, 10))\n",
    "selected_heatmap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print all local interpretability for GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_print= np.array([14359, 16238, 7399, 18593, 17478, 1635, 8273, 17546, 5412, 8464, 12148, 4764\n",
    "                 , 4629, 19019, 8670, 12221, 7087, 13267, 18238])\n",
    "label_data= np.array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n",
    "\n",
    "index_to_print -= 1\n",
    "\n",
    "index= 14359 - 1\n",
    "num_class= 1\n",
    "figsize= (10, 4)\n",
    "index_nothing_bilstm= np.array([144213])\n",
    "index_nothing_vanilla= np.array([155563, 155562])\n",
    "\n",
    "\n",
    "data_review_test= pd.read_csv(\"../GradCam/all_model_prediction.csv\")\n",
    "initial_review_tt= data_review_test[\"review\"].values\n",
    "\n",
    "initial_review= initial_review_tt[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_model_interpretability(index, m= \"max\", threshold= None, num_class= 1, heatmap_index= 1):\n",
    "    # CNN Character level\n",
    "    print(\"CNN Character level\")\n",
    "    h_c= cnn_char_gradcam(index, threshold= threshold, model= cpu_model, loader= test_data\n",
    "                     , type_map= m, num_class= num_class, figsize= figsize)\n",
    "    \n",
    "    # Vanilla Embed\n",
    "    print(\"Embed CNN\")\n",
    "    _, h_em= embed_gradcam(index, heatmap_index= heatmap_index, model= model_embed, threshold= threshold\n",
    "                                                      , data_loader= test_iterator_cnn_embed\n",
    "                                                      , type_map= m, vocab= word_ind_dict\n",
    "                                                      , num_class= num_class, figsize= figsize\n",
    "                                                      , index_nothing= index_nothing\n",
    "                                                      , initial_review= initial_review\n",
    "                                                      , figsize_second= (10, 10))\n",
    "    \n",
    "    # BILSTM Embed\n",
    "    print(\"BILSTM CNN\")\n",
    "    _, h_bi= embed_gradcam(index, heatmap_index= -1, model_type= \"bilstm\", threshold= threshold\n",
    "                                                      , model= cpu_bilstm_model\n",
    "                                                      , data_loader= test_batch_bilstm\n",
    "                                                      , type_map= m\n",
    "                                                      , vocab= word_ind_dict_bilstm\n",
    "                                                      , num_class= num_class, figsize= figsize\n",
    "                                                      , index_nothing= index_nothing\n",
    "                                                      , initial_review= initial_review\n",
    "                                                      , figsize_second= (10, 10))\n",
    "    return h_c, h_em, h_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# without threshold\n",
    "for i in range(index_to_print.shape[0]):\n",
    "    index= index_to_print[i]\n",
    "    print(\"\\n\")\n",
    "    print(index)\n",
    "    print(\"True label : {}\".format(label_data[i]))\n",
    "    print(\"\\n\")\n",
    "    initial_review= initial_review_tt[index]\n",
    "    print(initial_review)\n",
    "    print(\"\\n\")\n",
    "    print_all_model_interpretability(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with threshold\n",
    "for i in range(index_to_print.shape[0]):\n",
    "    index= index_to_print[i]\n",
    "    print(\"\\n\")\n",
    "    print(index)\n",
    "    print(\"True label : {}\".format(label_data[i]))\n",
    "    print(\"\\n\")\n",
    "    initial_review= initial_review_tt[index]\n",
    "    print(initial_review)\n",
    "    print(\"\\n\")\n",
    "    print_all_model_interpretability(index)#, threshold= 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index= 6177 #-1\n",
    "heatmap_index= -1\n",
    "num_class= 1\n",
    "print(\"\\n\")\n",
    "print(index)\n",
    "# print(\"True label : {}\".format(label_data[i]))\n",
    "print(\"\\n\")\n",
    "initial_review= initial_review_tt[index]\n",
    "print(initial_review)\n",
    "print(\"\\n\")\n",
    "print_all_model_interpretability(index, threshold= 0.75, num_class= num_class\n",
    "                                 , heatmap_index= heatmap_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text_and_heatmap(text= [\"ok\", \"salt\", \"ok\"]*3\n",
    "                      , heatmap= np.array([0, 1, 2]*3)\n",
    "                      , figsize= figsize\n",
    "                      , fontsize_text= \"medium\"\n",
    "                      , cmap= \"Greens\" #if type_map == \"max\" else \"PiYG\"\n",
    "                      , word_or_letter= \"word\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
