{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score alla data with all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from deep_nlp.cnncharclassifier import CNNCharClassifier, charToTensor\n",
    "from src.deep_nlp.embed_cnn.embcnnmodel_gradcam import classifier3F\n",
    "from deep_nlp.bilstm_cnn.bilstmcnn_gradcam import BilstmCnn\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "from deep_nlp.grad_cam.utils.letter import rebuild_text, prepare_heatmap, LetterToToken\n",
    "from deep_nlp.grad_cam.plot import plot_bar_heatmap, plot_text_and_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()  # this points to 'notebooks/' folder\n",
    "proj_path = current_dir.parent.parent \n",
    "print(proj_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "cnn_sequence_len= 1014\n",
    "cnn_feature_num= 87\n",
    "cnn_feature_size= 256\n",
    "cnn_kernel_one= 7\n",
    "cnn_kernel_two= 3\n",
    "cnn_stride_one= 1\n",
    "cnn_stride_two= 3\n",
    "cnn_output_linear= 1024\n",
    "cnn_num_class= 2\n",
    "cnn_dropout= 0.5\n",
    "cnn_cuda_allow= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_path_saved= \"data/06_models/cnn_char_classifier/cnn_char_model/cnn_char_model.pt\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + model_path_saved, 'rb') as f:\n",
    "    model_saved= pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_df= pd.read_csv(str(proj_path)+ \"\\\\\" + \"data/01_raw/allocine_test.csv\")\n",
    "\n",
    "test_data= charToTensor(data_df= data_df, sentence_max_size= cnn_sequence_len)\n",
    "\n",
    "test_load = DataLoader(test_data, batch_size= 1\n",
    "                       , num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "parameters = {\"sequence_len\": cnn_sequence_len, \"feature_num\": cnn_feature_num\n",
    "    , \"feature_size\": cnn_feature_size, \"kernel_one\": cnn_kernel_one\n",
    "    , \"kernel_two\": cnn_kernel_two, \"stride_one\": cnn_stride_one\n",
    "    , \"stride_two\": cnn_stride_two, \"output_linear\": cnn_output_linear\n",
    "    , \"num_class\": cnn_num_class, \"dropout\": cnn_dropout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNCharClassifier(**parameters)\n",
    "\n",
    "if cnn_cuda_allow:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.load_state_dict(model_saved)\n",
    "\n",
    "# state_dict= model.module.state_dict() # delete module to allow cpu loading\n",
    "\n",
    "# cpu_model= CNNCharClassifier(**parameters).cpu()\n",
    "# cpu_model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = []\n",
    "lab = []\n",
    "reviews= []\n",
    "alphabet= test_data.get_alphabet()+\" \"\n",
    "\n",
    "with torch.no_grad():\n",
    "    for review, label in test_load:\n",
    "        pred_test.append(torch.exp(model(review)))\n",
    "        lab.append(label.float())\n",
    "        \n",
    "pred_test = torch.cat(pred_test)\n",
    "lab = torch.cat(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_review_all= data_df[\"review\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame({\n",
    "    \"review\": text_review_all\n",
    "    , \"label\": lab\n",
    "    , \"cnn_char_proba_1\": pred_test.cpu()[:,1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding CNN (5 filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Test loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator_cnn_embed_path= \"data/02_intermediate/test_iterator_cnn_embed.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + test_iterator_cnn_embed_path, 'rb') as f:\n",
    "    test_iterator_cnn_embed= pickle.load(f)\n",
    "    \n",
    "print(type(test_iterator_cnn_embed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "embed_for_torch_path= \"data/04_feature/w2v_torch.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + embed_for_torch_path, 'rb') as f:\n",
    "    embed_for_torch= pickle.load(f)\n",
    "    \n",
    "print(type(embed_for_torch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ind_dict_path= \"data/04_feature/voc.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + word_ind_dict_path, 'rb') as f:\n",
    "    word_ind_dict= pickle.load(f)\n",
    "    \n",
    "print(type(word_ind_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "params_models = {\"wv\": embed_for_torch,\"no_words\": 67,\"embedding_dim\":200, \"nb_filter\":200\n",
    "                 , \"height_filter\":tuple([1, 2, 3, 4, 5]), \"output_dim\":2, \"dropout\":0.8, \"padded\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dict\n",
    "embed_cnn_model_for_save_path= \"data/06_models/embed_cnn/embed_cnn_classifier/embed_cnn.pt\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + embed_cnn_model_for_save_path, 'rb') as f:\n",
    "    embed_cnn_model_for_save= pickle.load(f)\n",
    "    \n",
    "print(type(embed_cnn_model_for_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classifier3F(**params_models)\n",
    "\n",
    "model.load_state_dict(embed_cnn_model_for_save)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = []\n",
    "lab = []\n",
    "reviews= []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for review, label in test_iterator_cnn_embed:\n",
    "        pred_test.append(model(review))\n",
    "        lab.append(label.float())\n",
    "        \n",
    "pred_test = torch.cat(pred_test)\n",
    "lab = torch.cat(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append prediction to df\n",
    "results[\"embed_cnn_proba_1\"]= pred_test.cpu()[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "embed_matrix_path= \"data/02_intermediate/bilstm_cnn/embed_matrix.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + embed_matrix_path, 'rb') as f:\n",
    "    embed_matrix= pickle.load(f)\n",
    "    \n",
    "print(type(embed_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "test_batch_bilstm_path= \"data/02_intermediate/test_iterator_cnn_bilstm.pkl\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + test_batch_bilstm_path, 'rb') as f:\n",
    "    test_batch_bilstm= pickle.load(f)\n",
    "    \n",
    "print(type(test_batch_bilstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BiLSTM + CNN\n",
    "num_epochs=  50\n",
    "batch_size= 32\n",
    "patience= 5\n",
    "lr= 0.001\n",
    "input_dim= 200\n",
    "hidden_dim= 128\n",
    "layer_dim= 2\n",
    "feature_size= 256\n",
    "output_dim= 2\n",
    "kernel_size= 3\n",
    "dropout_rate= 0.5\n",
    "sentence_size= 67\n",
    "padded= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "bilstm_cnn_model_for_save_path= \"data/06_models/bilstm_cnn/bilstm_cnn_classifier/bilstm_cnn.pt\"\n",
    "\n",
    "with open(str(proj_path)+ \"\\\\\" + bilstm_cnn_model_for_save_path, 'rb') as f:\n",
    "    bilstm_cnn_model_for_save= pickle.load(f)\n",
    "    \n",
    "print(type(bilstm_cnn_model_for_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BilstmCnn(embed_matrix, sentence_size, input_dim, hidden_dim\n",
    "                  , layer_dim, output_dim, feature_size, kernel_size, dropout_rate, padded)\n",
    "\n",
    "if cnn_cuda_allow:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.load_state_dict(bilstm_cnn_model_for_save)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = []\n",
    "lab = []\n",
    "reviews= []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for review, label in test_batch_bilstm:\n",
    "        test_reviews = review.to(torch.int64)\n",
    "#         test_labels = label.to(torch.int64)\n",
    "        \n",
    "        pred_test.append(model(test_reviews))\n",
    "        lab.append(label.float())\n",
    "        \n",
    "pred_test = torch.cat(pred_test)\n",
    "lab = torch.cat(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append prediction to df\n",
    "results[\"bilstm_cnn_proba_1\"]= pred_test.cpu()[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= lab.cpu().numpy()\n",
    "b= results[\"label\"].values\n",
    "sum(b == a) # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"all_model_prediction.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
