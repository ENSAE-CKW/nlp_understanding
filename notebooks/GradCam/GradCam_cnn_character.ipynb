{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Implémenter GradCAM au CNN à la maille caractère\n",
    "\n",
    "cf le travail de Khaled GracCam.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wenceslas\\Documents\\cours\\ENSAE\\2A\\Normal\\statapp\\nlp_understanding\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()  # this points to 'notebooks/' folder\n",
    "proj_path = current_dir.parent.parent \n",
    "print(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "# from deep_nlp.cnncharclassifier import CNNCharClassifier\n",
    "from deep_nlp.cnncharclassifier.char_to_tensor import charToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv(r\"../../data/01_raw/allocine_train.csv\")\n",
    "test_df= pd.read_csv(r\"../../data/01_raw/allocine_test.csv\")\n",
    "valid_df= pd.read_csv(r\"../../data/01_raw/allocine_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len= 1014\n",
    "feature_num= 256\n",
    "feature_size= 83\n",
    "kernel_one= 7\n",
    "kernel_two= 3\n",
    "stride_one= 1\n",
    "stride_two= 3\n",
    "output_linear= 1024\n",
    "num_class= 2\n",
    "dropout= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNNCharClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, sequence_len, feature_num, feature_size, kernel_one, kernel_two, stride_one, stride_two\n",
    "                 , output_linear, num_class, dropout):\n",
    "\n",
    "        super(CNNCharClassifier, self).__init__()  # legacy\n",
    "        self.sequence_len = sequence_len\n",
    "        self.feature_num = feature_num  # vocab size\n",
    "        self.feature_size = feature_size\n",
    "        self.kernel_one = kernel_one  # 7\n",
    "        self.kernel_two = kernel_two  # 3\n",
    "        self.stride_one = stride_one  # 1\n",
    "        self.stride_two = stride_two  # 3\n",
    "        self.input_linear = int(((self.sequence_len - 96) / 27) * self.feature_size)\n",
    "        self.output_linear = output_linear\n",
    "        self.num_class = int(num_class)  # 2\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(self.feature_num, self.feature_size, kernel_size=self.kernel_one, stride=self.stride_one),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=self.kernel_two, stride=self.stride_two)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(self.feature_size, self.feature_size, kernel_size=self.kernel_one, stride=self.stride_one),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=self.kernel_two, stride=self.stride_two)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(self.feature_size, self.feature_size, kernel_size=self.kernel_two, stride=self.stride_one),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(self.feature_size, self.feature_size, kernel_size=self.kernel_two, stride=self.stride_one),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(self.feature_size, self.feature_size, kernel_size=self.kernel_two, stride=self.stride_one),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv6_conv = nn.Conv1d(self.feature_size, self.feature_size\n",
    "                                    , kernel_size=self.kernel_two, stride=self.stride_one)\n",
    "        self.conv6_relu = nn.ReLU()\n",
    "        self.conv6_maxpool = nn.MaxPool1d(kernel_size=self.kernel_two, stride=self.stride_two)\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.input_linear, self.output_linear),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.output_linear, self.output_linear),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout)\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(self.output_linear, self.num_class)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self.weight_init()\n",
    "\n",
    "        self.before_conv = nn.Sequential()\n",
    "        self.before_conv.add_module(\"conv1\", self.conv1)\n",
    "        self.before_conv.add_module(\"conv2\", self.conv2)\n",
    "        self.before_conv.add_module(\"conv3\", self.conv3)\n",
    "        self.before_conv.add_module(\"conv4\", self.conv4)\n",
    "        self.before_conv.add_module(\"conv5\", self.conv5)\n",
    "        self.before_conv.add_module(\"conv6_conv\", self.conv6_conv)\n",
    "        self.before_conv.add_module(\"conv6_relu\", self.conv6_relu)\n",
    "\n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.pool = nn.Sequential()\n",
    "        self.pool.add_module(\"conv6_maxpool\", self.conv6_maxpool)\n",
    "\n",
    "        # get the max pool of the features stem\n",
    "        self.after_conv = nn.Sequential()\n",
    "        self.after_conv.add_module(\"fc1\", self.fc1)\n",
    "        self.after_conv.add_module(\"fc2\", self.fc2)\n",
    "        self.after_conv.add_module(\"fc3\", self.fc3)\n",
    "        self.after_conv.add_module(\"log_softmax\", self.log_softmax)\n",
    "\n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            try:\n",
    "                for m in self._modules[block]:\n",
    "                    nn.init.normal_(m, 0, 0.05)\n",
    "            except:\n",
    "                pass\n",
    "        pass\n",
    "\n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        pass\n",
    "\n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "\n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        x = self.before_conv(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.get_activations(x)\n",
    "        x = self.pool(x)\n",
    "        x= x.view(x.size(0), -1)\n",
    "        x = self.after_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "class GradCamBaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GradCamBaseModel, self).__init__()\n",
    "        \n",
    "        self.before_conv= nn.Sequential()\n",
    "        self.pool= nn.Sequential()\n",
    "        self.after_conv= nn.Sequential()\n",
    "        self.gradients= None\n",
    "    \n",
    "        pass\n",
    "    \n",
    "    def get_activations(self, x):\n",
    "        return self.before_conv(x)\n",
    "    \n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        pass\n",
    "\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    def get_hook(self, x):\n",
    "        return x.register_hook(self.activations_hook)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, *args):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1615,  0.0471, -0.7090,  0.1361],\n",
      "        [ 0.2502,  0.3742, -0.5975,  2.1507],\n",
      "        [ 0.6829, -0.2397,  0.2912,  0.0701],\n",
      "        [-0.5083,  1.3377, -1.2722, -0.4939]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1842,  0.3798, -0.5719,  0.4658])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "print(a)\n",
    "torch.mean(a, dim= [0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
