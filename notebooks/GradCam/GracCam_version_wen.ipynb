{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation de Grad Cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages et lecture du code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** IMPORTANT : à changer si utilisation du CPU ou du GPU **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wenceslas\\Documents\\cours\\ENSAE\\2A\\Normal\\statapp\\nlp_understanding\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()  # this points to 'notebooks/' folder\n",
    "proj_path = current_dir.parent.parent \n",
    "print(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "from src.deep_nlp.embed_cnn.embcnnmodel_gradcam import classifier3F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture de la classe `classifier3F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_cnn_model_class = os.path.join(proj_path,\"src\",\"deep_nlp\",\"embed_cnn\",\"embcnnmodel.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture des modèles déjà entraînés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset_train = os.path.join(proj_path,\"data\",\"02_intermediate\",\"allocine_train_inter.csv\")\n",
    "path_dataset_valid = os.path.join(proj_path,\"data\",\"02_intermediate\",\"allocine_valid_inter.csv\")\n",
    "path_dataset_test = os.path.join(proj_path,\"data\",\"02_intermediate\",\"allocine_test_inter.csv\")\n",
    "\n",
    "train_data = pd.read_csv(path_dataset_train, dtype = \"int64\")\n",
    "val_data = pd.read_csv(path_dataset_valid, dtype = \"int64\")\n",
    "test_data = pd.read_csv(path_dataset_test, dtype = \"int64\")\n",
    "\n",
    "train_tensor_x = torch.from_numpy(train_data.drop(columns=[\"label\"]).to_numpy()).to(device).long()\n",
    "train_tensor_y = torch.from_numpy(train_data[\"label\"].to_numpy()).to(device).long()\n",
    "\n",
    "val_tensor_x = torch.from_numpy(val_data.drop(columns=[\"label\"]).to_numpy()).to(device).long()\n",
    "val_tensor_y = torch.from_numpy(val_data[\"label\"].to_numpy()).to(device).long()\n",
    "\n",
    "test_tensor_x = torch.from_numpy(test_data.drop(columns=[\"label\"]).to_numpy()).to(device).long()\n",
    "test_tensor_y = torch.from_numpy(test_data[\"label\"].to_numpy()).to(device).long()\n",
    "\n",
    "train_data = TensorDataset(train_tensor_x,train_tensor_y)\n",
    "test_data = TensorDataset(test_tensor_x, test_tensor_y)\n",
    "valid_data = TensorDataset(val_tensor_x, val_tensor_y)\n",
    "\n",
    "train_load = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "val_load = torch.utils.data.DataLoader(dataset= valid_data,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "test_load = torch.utils.data.DataLoader(dataset= test_data,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un dictionnaire contenant le vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_vocab = os.path.join(proj_path,\"data\",\"04_feature\",\"voc.pkl\")\n",
    "\n",
    "#Embedding reading\n",
    "with open(path_vocab, 'rb') as f:\n",
    "    vocab = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_reverse = {y:x for x,y in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture de l'embedding (Word2vec French) sauvegardé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_embed_pytorch = os.path.join(proj_path,\"data\",\"04_feature\",\"w2v_torch.pkl\")\n",
    "\n",
    "#Embedding reading\n",
    "with open(path_embed_pytorch, 'rb') as f:\n",
    "    embed_for_torch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un dictionnaire contenant les paramètres pour le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_models = {\"wv\": embed_for_torch,\"no_words\": 67,\"embedding_dim\":200, \"nb_filter\":600\n",
    "                 , \"height_filter\":tuple([1, 2]), \"output_dim\":2, \"dropout\":0.6, \"padded\":True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier3F(\n",
       "  (before_conv): Sequential(\n",
       "    (conv1_conv_1): Conv2d(1, 600, kernel_size=(1, 200), stride=(1, 1))\n",
       "    (conv1_conv_2): Conv2d(1, 600, kernel_size=(2, 200), stride=(1, 1))\n",
       "    (conv1_relu): ReLU()\n",
       "  )\n",
       "  (pool): Sequential(\n",
       "    (conv1_maxpool): Sequential(\n",
       "      (0): MaxPool1d(kernel_size=67, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (after_conv): Sequential(\n",
       "    (dp): Dropout(p=0.6, inplace=False)\n",
       "    (fc): Linear(in_features=1200, out_features=2, bias=True)\n",
       "    (sm): Softmax(dim=1)\n",
       "  )\n",
       "  (embedding): Embedding(155564, 200)\n",
       "  (conv1_conv): ModuleList(\n",
       "    (0): Conv2d(1, 600, kernel_size=(1, 200), stride=(1, 1))\n",
       "    (1): Conv2d(1, 600, kernel_size=(2, 200), stride=(1, 1))\n",
       "  )\n",
       "  (conv1_relu): ReLU()\n",
       "  (conv1_maxpool): Sequential(\n",
       "    (0): MaxPool1d(kernel_size=67, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=1200, out_features=2, bias=True)\n",
       "  (sm): Softmax(dim=1)\n",
       "  (dp): Dropout(p=0.6, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_trained_model = os.path.join(proj_path,\"data\",\"06_models\",\"embed_cnn\",\"embed_cnn_classifier\"\n",
    "                                  ,\"embed_cnn.pt\")\n",
    "\n",
    "#Embedding reading\n",
    "with open(path_trained_model, 'rb') as f:\n",
    "    model_weight = pickle.load(f)\n",
    "\n",
    "model = classifier3F(**params_models)\n",
    "\n",
    "model.load_state_dict(model_weight)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.        , 0.        , 0.9047118 , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.37796643, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.74841446,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ], dtype=float32),\n",
       " array([1.8510653e-02, 3.9093307e-01, 1.0000000e+00, 8.8461854e-02,\n",
       "        2.1580376e-02, 1.1402175e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.5512248e-02, 1.5512248e-02, 1.5512248e-02, 1.5512248e-02,\n",
       "        1.5512248e-02, 4.4644588e-01, 0.0000000e+00, 8.5265398e-05,\n",
       "        2.7269381e-01, 4.0866819e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00], dtype=float32),\n",
       " array([4.11320856e-04, 4.81732726e-01, 1.00000000e+00, 7.22442642e-02,\n",
       "        1.59565344e-01, 7.12495595e-02, 6.26565039e-01, 7.85146877e-02,\n",
       "        7.31830671e-03, 7.31830671e-03, 7.31830671e-03, 7.31830671e-03,\n",
       "        7.31830671e-03, 9.63398397e-01, 1.08090945e-01, 2.34338008e-02,\n",
       "        2.94293910e-01, 3.68333548e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text test\n",
    "test_text,_ = next(iter(test_load))\n",
    "output_test= model(test_text)\n",
    "\n",
    "model.get_heatmap(text= test_text\n",
    "                , num_class= 0\n",
    "                , dim= [0, 2]\n",
    "                , type_map= \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = []\n",
    "lab = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for review,label in test_load:\n",
    "    pred_test.append(model(review))\n",
    "    lab.append(label.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = torch.cat(pred_test).cpu()\n",
    "lab = torch.cat(lab).cpu()\n",
    "#define metric\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds[:,1])    \n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "binary_accuracy(pred_test, lab.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradCam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la classe GradCam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'instant, j'essaye d'implémenter GradCam uniquement pour le modèle Embedding + CNN. Je modifirai la classe plus tard pour qu'elle soit plus générale.\n",
    "Il faudra peut être utiliser `test = [element for element in model.modules()]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class embed_cnn_gradcam(nn.Module):\n",
    "    def __init__(self, before_conv, pool, after_conv,model):\n",
    "        super(embed_cnn_gradcam, self).__init__()\n",
    "        \n",
    "        # get the pretrained VGG19 network\n",
    "        self.before_conv = before_conv\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.pool = pool\n",
    "        \n",
    "        # get the max pool of the features stem\n",
    "        self.after_conv = after_conv\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.before_conv.embed(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        if model.padded: #attention pb transpose ?\n",
    "            x_padded = [nn.ZeroPad2d((0, 0, 0, height - 1))(x) for height in model.height_filter]\n",
    "            x_padded = list(zip(x_padded,self.before_conv.conv))\n",
    "            x = [conv(x).squeeze(2).squeeze(2) for x,conv in x_padded]\n",
    "        else:\n",
    "            x = [conv(x).squeeze(2).squeeze(2) for conv in self.before_conv.conv]\n",
    "        x = x[0] #change latter    \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.squeeze(2).squeeze(2) #TODO : utilisez une autre fonction récursive qui squeeze\n",
    "        x = self.after_conv(x)\n",
    "        return x\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        x = self.before_conv.embed(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        if model.padded:\n",
    "            x_padded = [nn.ZeroPad2d((0, 0, 0, height - 1))(x) for height in model.height_filter]\n",
    "            x_padded = list(zip(x_padded,self.before_conv.conv))\n",
    "            x = [conv(x).squeeze(2).squeeze(2) for x,conv in x_padded]\n",
    "        else:\n",
    "            x = [conv(x).squeeze(2).squeeze(2) for conv in self.before_conv.conv]\n",
    "        x = x[0] #change latter\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application à la classe `classifier3F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_conv = nn.Sequential()\n",
    "before_conv.add_module(\"embed\", model.embedding)\n",
    "before_conv.add_module(\"conv\", [conv[:-1] for conv in model.conv.children()][0]) #Ici c'est en mode séquential alors que si on a plusieurs filtres, on est avec un ModuleList. Pb avec le forward quand on utilise\n",
    "#un module list..\n",
    "\n",
    "pool = nn.Sequential()\n",
    "pool.add_module(\"pool\",[conv[-1] for conv in model.conv.children()][0]) #~à changer quand plusieurs filtres\n",
    "\n",
    "after_conv = nn.Sequential()\n",
    "after_conv.add_module(\"fc\", model.fc)\n",
    "after_conv.add_module(\"sm\", model.sm)\n",
    "after_conv.add_module(\"dp\", model.dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam_cnn = embed_cnn_gradcam(before_conv, pool, after_conv,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicaiton à un exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explication(test_text, before_conv, pool, after_conv,model):\n",
    "    gradcam_cnn = embed_cnn_gradcam(before_conv, pool, after_conv,model)\n",
    "    pred = gradcam_cnn(test_text)\n",
    "    gradcam_cnn(test_text)[0,0].backward()\n",
    "    gradients = gradcam_cnn.get_activations_gradient()\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    activations = gradcam_cnn.get_activations(test_text).detach()\n",
    "    for i in range(activations.shape[1]):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= torch.max(heatmap)\n",
    "    res = pd.DataFrame({\"index\":test_text.squeeze().numpy(), \"explanations\":heatmap.numpy()})\n",
    "    res[\"word\"] = pd.Series([vocab_reverse.get(index, \"\") for index in test_text.squeeze().numpy()])\n",
    "    res.sort_values(by='explanations', ascending=False, inplace = True)\n",
    "    return {\"resultat\":res,\"prob\":gradcam_cnn(test_text)[0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Récupère les résultats de explication et renvoie seulement les mots dont l'explnation est supérieure a un seuil\n",
    "def explication_seuil(ex, seuil):\n",
    "    resultat = ex[\"resultat\"]\n",
    "    mots_expliquants = list(resultat[resultat[\"explanations\"] > seuil][\"word\"])\n",
    "    return {\"mots_expli\": mots_expliquants, \"prob\": ex[\"prob\"].item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "explained = []\n",
    "i = 0\n",
    "for review,label in test_load:\n",
    "    ex = explication(review,before_conv,pool,after_conv,model)\n",
    "    explications_pour_plot = explication_seuil(ex,0.75)\n",
    "    res.append([explications_pour_plot,label])\n",
    "    i += 1\n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_plus_75 = [element[0][\"mots_expli\"] for element in res if element[0][\"prob\"] > 0.75]\n",
    "mots_50_75 = [element[0][\"mots_expli\"] for element in res if (element[0][\"prob\"] > 0.5) & (element[0][\"prob\"] < 0.75)]\n",
    "mots_25_50 = [element[0][\"mots_expli\"] for element in res if (element[0][\"prob\"] > 0.25) & (element[0][\"prob\"] < 0.5)]\n",
    "mots_0_25 = [element[0][\"mots_expli\"] for element in res if (element[0][\"prob\"] < 0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mots = [element[0][\"mots_expli\"] for element in res]\n",
    "prob = [element[0][\"prob\"] for element in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faire table ind pour les mots + prob puis faire une ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "mots_plus_75 = list(itertools.chain.from_iterable(mots_plus_75))\n",
    "mots_50_75 = list(itertools.chain.from_iterable(mots_50_75))\n",
    "mots_25_50 = list(itertools.chain.from_iterable(mots_25_50))\n",
    "mots_0_25 = list(itertools.chain.from_iterable(mots_0_25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "mots_plus_75 = pd.DataFrame.from_dict(Counter(mots_plus_75),orient=\"index\")\n",
    "\n",
    "mots_plus_75 = mots_plus_75.sort_values(by=0, ascending = False)\n",
    "\n",
    "mots_plus_75.head(30).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_0_25_df = pd.DataFrame.from_dict(Counter(mots_0_25),orient=\"index\")\n",
    "\n",
    "mots_0_25_df = mots_0_25_df.sort_values(by=0, ascending = False)\n",
    "\n",
    "mots_0_25_df.head(30).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Define a function to plot word cloud\n",
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuage de mots pour les prédictions à plus de 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='salmon', colormap='Pastel1', collocations=False, stopwords = STOPWORDS).generate(\" \".join(mots_0_25))\n",
    "# Plot\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud2 = WordCloud(width = 3000, height = 2000, random_state=1,background_color='salmon', colormap='Pastel1', collocations=False, stopwords = STOPWORDS).generate(\" \".join(mots_25_50))\n",
    "# Plot\n",
    "plot_cloud(wordcloud2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
